
import streamlit as st
import requests
import json
import google.generativeai as genai
from google.generativeai.types import HarmCategory, HarmBlockThreshold
import re
import time
import datetime
import random
import urllib.parse
import html
import textwrap

# -----------------------------------------------------------------------------
# 0. DEPENDENCY CHECK
# -----------------------------------------------------------------------------
try:
    import feedparser
except ImportError:
    st.error("‚ùå Áº∫Â∞ëÂøÖË¶ÅÁªÑ‰ª∂Ôºöfeedparser„ÄÇËØ∑Âú® requirements.txt ‰∏≠Ê∑ªÂä† 'feedparser' ÊàñËøêË°å pip install feedparser„ÄÇ")
    st.stop()

# ================= üîê 1. KEY MANAGEMENT =================
try:
    EXA_API_KEY = st.secrets.get("EXA_API_KEY", None)
    GOOGLE_API_KEY = st.secrets.get("GOOGLE_API_KEY", None)
    NEWS_API_KEY = st.secrets.get("NEWS_API_KEY", None)
    KEYS_LOADED = True
except:
    EXA_API_KEY = None
    GOOGLE_API_KEY = None
    NEWS_API_KEY = None
    KEYS_LOADED = False

if GOOGLE_API_KEY:
    genai.configure(api_key=GOOGLE_API_KEY)

# ================= üõ†Ô∏è DEPENDENCY CHECK (EXA) =================
try:
    from exa_py import Exa
    EXA_AVAILABLE = True
except ImportError:
    EXA_AVAILABLE = False

# ================= üïµÔ∏è‚Äç‚ôÇÔ∏è 2. SYSTEM CONFIGURATION =================
st.set_page_config(
    page_title="Be Holmes | News Analysis",
    page_icon="üïµÔ∏è‚Äç‚ôÇÔ∏è",
    layout="wide",
    initial_sidebar_state="collapsed"
)

# ================= üß† 3. STATE MANAGEMENT =================
default_state = {
    "messages": [],
    "current_market": None,
    "search_candidates": [],     # Stores list of found markets
    "search_stage": "input",     # input -> selection -> analysis
    "user_news_text": "",
    "is_processing": False,
    "last_user_input": "",
    "news_category": "all",
    "market_sort": "volume",
    "debug_logs": []             # Store debug info
}

for key, value in default_state.items():
    if key not in st.session_state:
        st.session_state[key] = value

# ================= üé® 4. UI THEME (MOBILE OPTIMIZED VERSION) =================
st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;600;900&family=Plus+Jakarta+Sans:wght@400;700&display=swap');
    @import url('https://fonts.googleapis.com/css2?family=JetBrains+Mono:wght@400;700&display=swap');

    /* === Global Background === */
    .stApp {
        background-image: linear-gradient(rgba(0, 0, 0, 0.92), rgba(20, 0, 0, 0.96)), 
                          url('https://upload.cc/i1/2026/01/20/s8pvXA.jpg');
        background-size: cover;
        background-position: center;
        background-attachment: fixed;
        font-family: 'Inter', sans-serif;
    }
    
    /* === üì± Mobile Layout Optimization === */
    /* Reduce padding on mobile devices to maximize screen real estate */
    .block-container {
        padding-top: 2rem !important;
        padding-bottom: 4rem !important;
        padding-left: 1rem !important;
        padding-right: 1rem !important;
    }

    /* === Hero Title (Responsive) === */
    .hero-title {
        font-family: 'Inter', sans-serif;
        font-weight: 700;
        font-size: 3.5rem; 
        color: #ffffff;
        text-align: center;
        letter-spacing: -2px;
        margin-bottom: 5px;
        padding-top: 2vh;
        text-shadow: 0 0 30px rgba(220, 38, 38, 0.6);
        line-height: 1.1;
    }
    .hero-subtitle {
        font-family: 'Plus Jakarta Sans', sans-serif;
        font-size: 1rem;
        color: #9ca3af; 
        text-align: center;
        margin-bottom: 25px;
        font-weight: 400;
    }
    
    /* Adjust Title size for mobile */
    @media (max-width: 600px) {
        .hero-title { font-size: 2.2rem; letter-spacing: -1px; }
        .hero-subtitle { font-size: 0.9rem; margin-bottom: 15px; }
    }

    /* === Fixed Time Zone Bar (Responsive) === */
    .world-clock-bar {
        display: flex; 
        justify-content: space-between; 
        background: rgba(0,0,0,0.5); 
        padding: 8px 10px; 
        border-radius: 6px; 
        margin-bottom: 15px;
        border: 1px solid rgba(220, 38, 38, 0.2);
        font-family: 'JetBrains Mono', monospace;
        flex-wrap: wrap; /* Wrap content on small screens */
        gap: 5px;
    }
    .clock-item { font-size: 0.7rem; color: #9ca3af; display: flex; align-items: center; gap: 4px; }
    .clock-item b { color: #e5e7eb; font-weight: 700; }
    .clock-time { color: #f87171; }

    /* === Buttons === */
    div.stButton > button {
        background: linear-gradient(90deg, #991b1b 0%, #7f1d1d 100%) !important;
        color: white !important;
        border: 1px solid #b91c1c !important;
        border-radius: 8px !important;
        font-weight: 600 !important;
        transition: all 0.3s !important;
    }
    div.stButton > button:hover {
        background: linear-gradient(90deg, #dc2626 0%, #b91c1c 100%) !important;
        box-shadow: 0 0 15px rgba(220, 38, 38, 0.6) !important;
        border-color: #fca5a5 !important;
        transform: scale(1.02) !important;
    }

    /* === News Cards (Responsive) === */
    .news-grid-card {
        background: rgba(20, 0, 0, 0.6);
        border: 1px solid rgba(255, 255, 255, 0.05);
        border-left: 3px solid #dc2626;
        border-radius: 8px;
        padding: 15px;
        height: 100%;
        min-height: 140px;
        display: flex;
        flex-direction: column;
        justify-content: space-between;
        transition: all 0.3s ease-in-out;
    }
    /* Mobile: Allow height to grow based on content */
    @media (max-width: 600px) {
        .news-grid-card { min-height: auto; margin-bottom: 10px; }
    }
    .news-grid-card:hover {
        background: rgba(40, 0, 0, 0.8);
        border-color: #ef4444;
        box-shadow: 0 0 15px rgba(220, 38, 38, 0.2);
        transform: translateY(-2px);
    }
    .news-meta {
        font-size: 0.7rem;
        color: #fca5a5;
        font-weight: 600;
        margin-bottom: 8px;
        display: flex;
        justify-content: space-between;
    }
    .news-body {
        font-size: 0.9rem;
        color: #e5e7eb;
        line-height: 1.4;
        font-weight: 500;
        margin-bottom: 15px;
        display: -webkit-box;
        -webkit-line-clamp: 3;
        -webkit-box-orient: vertical;
        overflow: hidden;
    }
    
    /* === Market Card Modern (Responsive) === */
    .market-card-modern {
        background: rgba(255, 255, 255, 0.02);
        border: 1px solid rgba(255, 255, 255, 0.1);
        border-radius: 8px;
        padding: 12px;
        margin-bottom: 10px;
        transition: all 0.2s;
        cursor: pointer;
    }
    .market-card-modern:hover {
        border-color: #ef4444;
        background: rgba(40, 0, 0, 0.3);
        transform: translateY(-2px);
    }
    .market-head {
        display: flex;
        justify-content: space-between;
        align-items: flex-start;
        margin-bottom: 10px;
    }
    /* Mobile: Stack title and volume if needed */
    @media (max-width: 600px) {
        .market-head { flex-direction: column; }
        .market-title-mod { margin-bottom: 5px; }
    }
    .market-title-mod {
        font-size: 0.85rem;
        color: #e5e7eb;
        font-weight: 600;
        line-height: 1.3;
        flex: 1;
        margin-right: 10px;
    }
    .market-vol {
        font-size: 0.7rem;
        color: #9ca3af;
        white-space: nowrap;
        background: rgba(255,255,255,0.05);
        padding: 2px 6px;
        border-radius: 4px;
        font-family: 'JetBrains Mono', monospace;
    }
    .outcome-row {
        display: flex;
        justify-content: space-between;
        gap: 10px;
    }
    .outcome-box {
        flex: 1;
        padding: 8px;
        border-radius: 6px;
        display: flex;
        justify-content: space-between;
        align-items: center;
        font-family: 'JetBrains Mono', monospace;
    }
    .outcome-box.yes { background: rgba(16, 185, 129, 0.1); border: 1px solid rgba(16, 185, 129, 0.2); }
    .outcome-box.no { background: rgba(239, 68, 68, 0.1); border: 1px solid rgba(239, 68, 68, 0.2); }
    .outcome-label { font-size: 0.75rem; font-weight: 600; }
    .outcome-price { font-size: 1rem; font-weight: 700; }
    .yes-color { color: #10b981; }
    .no-color { color: #ef4444; }

    /* === Input Area === */
    .stTextArea textarea {
        background-color: rgba(20, 0, 0, 0.6) !important;
        border: 1px solid #7f1d1d !important;
        color: white !important;
        border-radius: 12px !important;
        font-size: 1rem !important;
    }
    .stTextArea textarea:focus {
        border-color: #ef4444 !important;
        box-shadow: 0 0 10px rgba(220, 38, 38, 0.4) !important;
    }
    
    /* === Analysis Card === */
    .analysis-card {
        background: rgba(20, 0, 0, 0.8);
        border: 1px solid #7f1d1d;
        border-radius: 12px;
        padding: 20px;
        margin-top: 20px;
        margin-bottom: 20px;
    }
    
    /* === Chat Input styling === */
    .stChatInput input {
        background-color: rgba(20, 0, 0, 0.6) !important;
        color: white !important;
        border: 1px solid #7f1d1d !important;
    }

    /* === Hub Button === */
    .hub-btn {
        display: flex;
        flex-direction: column;
        align-items: center;
        justify-content: center;
        width: 100%;
        height: 70px;
        background: rgba(255, 255, 255, 0.03);
        border: 1px solid rgba(255, 255, 255, 0.08);
        border-radius: 10px;
        text-align: center;
        text-decoration: none;
        transition: all 0.3s cubic-bezier(0.4, 0, 0.2, 1);
        backdrop-filter: blur(5px);
        margin-bottom: 10px;
        cursor: pointer;
    }
    .hub-btn:hover {
        background: rgba(40, 0, 0, 0.6);
        border-color: #ef4444;
        transform: translateY(-3px);
        box-shadow: 0 5px 15px rgba(220, 38, 38, 0.3);
    }
    .hub-content { display: flex; flex-direction: column; align-items: center; }
    .hub-emoji { font-size: 1.4rem; line-height: 1.2; margin-bottom: 4px; filter: grayscale(0.2); }
    .hub-btn:hover .hub-emoji { filter: grayscale(0); transform: scale(1.1); transition: transform 0.2s;}
    .hub-text { 
        font-family: 'Inter', sans-serif;
        font-size: 0.8rem; 
        color: #d1d5db; 
        font-weight: 600; 
        letter-spacing: 0.5px;
    }
    .hub-btn:hover .hub-text { color: #ffffff; }
    
    /* === Global Trends Buttons (Fixed & Responsive) === */
    .trend-row { 
        display: flex; 
        gap: 8px; 
        flex-wrap: wrap; 
        margin-bottom: 20px; 
        justify-content: flex-start; 
    }
    .trend-fixed-btn {
        background: rgba(220, 38, 38, 0.1);
        border: 1px solid rgba(220, 38, 38, 0.3);
        color: #fca5a5;
        padding: 6px 14px;
        border-radius: 6px;
        font-size: 0.8rem;
        font-weight: 600;
        text-decoration: none;
        display: flex;
        align-items: center;
        gap: 6px;
        transition: all 0.2s;
        white-space: nowrap; /* Prevent breaking inside button */
    }
    .trend-fixed-btn:hover {
        background: rgba(220, 38, 38, 0.4);
        color: white;
        border-color: #ef4444;
        transform: translateY(-2px);
    }
    
    /* Small screen tweaks */
    @media (max-width: 400px) {
        .trend-fixed-btn { font-size: 0.7rem; padding: 5px 10px; }
        .hub-text { font-size: 0.7rem; }
    }
    
    .ex-link {
        font-size: 0.7rem; color: #6b7280; text-decoration: none; margin-top: 5px; display: block; text-align: right;
    }
    .ex-link:hover { color: #ef4444; }
</style>
""", unsafe_allow_html=True)

# ================= üß† 5. LOGIC CORE =================

# --- üî• A. Crypto Prices (Extended List) ---
@st.cache_data(ttl=60)
def fetch_crypto_prices_v2():
    symbols = [
        "BTCUSDT", "ETHUSDT", "SOLUSDT", "BNBUSDT", "XRPUSDT", 
        "DOGEUSDT", "ADAUSDT", "AVAXUSDT", "SHIBUSDT", "DOTUSDT", 
        "LINKUSDT", "TRXUSDT", "MATICUSDT", "LTCUSDT", "BCHUSDT", 
        "UNIUSDT", "NEARUSDT", "APTUSDT", "FILUSDT", "ICPUSDT",
        "PEPEUSDT", "WIFUSDT", "SUIUSDT", "FETUSDT"
    ]
    crypto_data = []
    try:
        url = "https://api.binance.com/api/v3/ticker/24hr"
        response = requests.get(url, timeout=5)
        if response.status_code == 200:
            all_tickers = {t['symbol']: t for t in response.json()}
            for sym in symbols:
                if sym in all_tickers:
                    ticker = all_tickers[sym]
                    symbol_clean = sym.replace('USDT', '')
                    price = float(ticker['lastPrice'])
                    change_24h = float(ticker['priceChangePercent'])
                    volume = float(ticker['volume'])
                    
                    if price >= 1000: price_str = f"${price:,.0f}"
                    elif price >= 1: price_str = f"${price:,.2f}"
                    else: price_str = f"${price:.4f}"
                    
                    if volume >= 1000000: vol_str = f"{volume/1000000:.1f}M"
                    elif volume >= 1000: vol_str = f"{volume/1000:.1f}K"
                    else: vol_str = f"{volume:.0f}"
                    
                    crypto_data.append({
                        "symbol": symbol_clean,
                        "price": price_str,
                        "change": change_24h,
                        "volume": vol_str,
                        "trend": "up" if change_24h > 0 else "down"
                    })
    except: pass 
    if not crypto_data:
        crypto_data = [{"symbol": "BTC", "price": "$94,250", "change": 2.3, "volume": "25.5B", "trend": "up"}]
    return crypto_data

# --- üî• B. Categorized News Fetcher ---
@st.cache_data(ttl=300)
def fetch_categorized_news_v2():
    def fetch_rss(url, limit=20):
        items = []
        try:
            feed = feedparser.parse(url)
            for entry in feed.entries[:limit]:
                time_display = "Recent"
                if hasattr(entry, 'published_parsed'):
                    try:
                        dt = datetime.datetime.fromtimestamp(time.mktime(entry.published_parsed))
                        diff = datetime.datetime.now() - dt
                        if diff.total_seconds() < 3600: time_display = f"{int(diff.total_seconds()/60)}m ago"
                        else: time_display = f"{int(diff.total_seconds()/3600)}h ago"
                    except: pass
                items.append({
                    "title": entry.title,
                    "source": entry.get("source", {}).get("title", "News"),
                    "link": entry.link,
                    "time": time_display
                })
        except: pass
        return items

    feeds = {
        "all": "https://news.google.com/rss?hl=en-US&gl=US&ceid=US:en",
        "politics": "https://rss.nytimes.com/services/xml/rss/nyt/Politics.xml",
        "tech": "https://techcrunch.com/feed/",
        "web3": "https://www.coindesk.com/arc/outboundfeeds/rss/"
    }
    return {k: fetch_rss(v, 30) for k, v in feeds.items()}

# --- üî• C. Polymarket Fetcher (ENHANCED - supports Sub-markets & Liquidity) ---
def process_polymarket_event(event):
    """
    Core function to process ANY Polymarket event.
    Returns standardized data structure tailored for generate_market_context.
    """
    try:
        title = event.get('title', 'Untitled').strip()
        if not title: return None
        
        # 1. Sensitive Keyword Filter
        SENSITIVE_KEYWORDS = ["china", "chinese", "xi jinping", "taiwan", "ccp", "beijing", "hong kong", "communist"]
        if any(kw in title.lower() for kw in SENSITIVE_KEYWORDS): return None

        # 2. Status Filter
        if event.get('closed') is True: return None
        if not event.get('markets'): return None
        
        # 3. Find Main Market (Highest Volume)
        markets_list = event.get('markets', [])
        markets_list.sort(key=lambda x: float(x.get('volume', 0) or 0), reverse=True)
        m = markets_list[0]
        
        vol = float(m.get('volume', 0) or 0)
        if vol < 1000: return None # Filter Dead Markets
        
        # --- NEW: Extract Data for Context Generator ---
        # Liquidity
        liquidity = float(m.get('liquidity', 0) or 0)
        
        # 24h Price Change
        change_24h = float(m.get('oneDayPriceChange', 0) or m.get('priceChange24h', 0) or 0)

        # Volume String Formatting
        if vol >= 1000000: vol_str = f"${vol/1000000:.1f}M"
        elif vol >= 1000: vol_str = f"${vol/1000:.0f}K"
        else: vol_str = f"${vol:.0f}"

        # 4. Parse Odds (Robust)
        outcomes = json.loads(m.get('outcomes')) if isinstance(m.get('outcomes'), str) else m.get('outcomes')
        prices = json.loads(m.get('outcomePrices')) if isinstance(m.get('outcomePrices'), str) else m.get('outcomePrices')
        
        outcome_data = []
        if outcomes and prices:
            for i, out in enumerate(outcomes):
                if i < len(prices):
                    try:
                        # Price is usually 0.72 in API, convert to percentage for list, keep decimal for context
                        raw_price = float(prices[i]) 
                        prob_percent = raw_price * 100
                        outcome_data.append((str(out), prob_percent, raw_price))
                    except: continue
        
        if not outcome_data: return None

        # Sort by Probability (High to Low)
        outcome_data.sort(key=lambda x: x[1], reverse=True)
        
        # Get Top Probability (0.0 - 1.0 format) for the Generator
        top_prob_decimal = outcome_data[0][2] 
        
        # Format Top 3 Odds for Display
        top_odds = [f"{o}: {p:.1f}%" for o, p, r in outcome_data[:3]]
        odds_str = " | ".join(top_odds)

        # 5. Extract Details for All Sub-Markets (V1.3 UPGRADE)
        all_sub_markets = []
        # We process the top 6 sub-markets to provide rich context
        for sub_m in markets_list[:6]:
            try:
                # Basic sub-market data
                q_text = sub_m.get('question', title)
                sub_out = json.loads(sub_m.get('outcomes')) if isinstance(sub_m.get('outcomes'), str) else sub_m.get('outcomes')
                sub_pri = json.loads(sub_m.get('outcomePrices')) if isinstance(sub_m.get('outcomePrices'), str) else sub_m.get('outcomePrices')
                sub_vol = float(sub_m.get('volume', 0) or 0)
                
                # Determine top outcome for this sub-market
                best_opt = ""
                best_price = 0.0
                if sub_out and sub_pri:
                    temp_ops = []
                    for i, o in enumerate(sub_out):
                        if i < len(sub_pri):
                            try:
                                p_val = float(sub_pri[i])
                                temp_ops.append((o, p_val))
                            except: continue
                    temp_ops.sort(key=lambda x: x[1], reverse=True)
                    if temp_ops:
                        best_opt = temp_ops[0][0]
                        best_price = temp_ops[0][1]

                # Structure for UI
                sub_data = {
                    "question": q_text,
                    "volume": sub_vol,
                    "type": "binary" if len(sub_out) == 2 else "multiple",
                    "options": [],
                    # Extra fields for Context Generator
                    "top_option": best_opt,
                    "top_price": best_price
                }
                
                # Fill options for UI
                if len(sub_out) == 2 and "Yes" in sub_out and "No" in sub_out:
                    y_idx = sub_out.index("Yes")
                    n_idx = sub_out.index("No")
                    sub_data['yes_price'] = float(sub_pri[y_idx]) * 100 if y_idx < len(sub_pri) else 0
                    sub_data['no_price'] = float(sub_pri[n_idx]) * 100 if n_idx < len(sub_pri) else 0
                else:
                    for i, o in enumerate(sub_out):
                        if i < len(sub_pri):
                            sub_data['options'].append({
                                "option": str(o), 
                                "price": float(sub_pri[i]) * 100
                            })
                all_sub_markets.append(sub_data)
            except: continue

        # Return standardized dict matching generate_market_context requirements
        return {
            "title": title,
            "slug": event.get('slug', ''),
            "volume": vol,
            "vol_str": vol_str, # This is the formatted string (e.g. $50M)
            "odds": odds_str,
            "url": f"https://polymarket.com/event/{event.get('slug', '')}",
            "markets": all_sub_markets,
            
            # Fields specifically for generate_market_context:
            "probability": top_prob_decimal, # 0.72
            "liquidity": liquidity,          # 150000.0
            "change_24h": change_24h         # 0.05
        }
    except: return None

@st.cache_data(ttl=60)
def fetch_polymarket_v5_simple(limit=60, sort_mode='volume'):
    """
    Fetch Top Markets for Homepage.
    Supports server-side sorting with robust fallback.
    """
    try:
        base_url = "https://gamma-api.polymarket.com/events?closed=false"
        
        # 1. Attempt API Sorting (Try sorting by volume or liquidity)
        if sort_mode == 'volume':
            # Try getting top liquidity/volume events (API dependent)
            # Increased limit to 500 to catch old whales if API sort fails
            api_url = f"{base_url}&limit=500" 
        else:
            # Active/Trending
            api_url = f"{base_url}&limit=50"

        resp = requests.get(api_url, timeout=12) 
        
        # Fallback if API fails
        if resp.status_code != 200:
            return []

        data = resp.json()
        markets = []
        
        if isinstance(data, list):
            for event in data:
                market_data = process_polymarket_event(event)
                if market_data:
                    markets.append(market_data)
        
        # 2. Strong Local Sort (Crucial for "Volume" view)
        if sort_mode == 'volume':
            markets.sort(key=lambda x: x['volume'], reverse=True)
        # 'active' usually implies the default API return order (Trending)
            
        return markets[:limit]
    except Exception as e:
        return []

# --- üî• ROBUST FACT CHECKER (Exa V1.9) ---
def verify_news_with_exa(query):
    """
    Searches EXA for the news topic itself (not just markets) to verify authenticity.
    Uses 'auto' type which is the most robust.
    """
    if not EXA_AVAILABLE or not EXA_API_KEY: 
        return "‚ö†Ô∏è Êó†Ê≥ïËøõË°åÂÖ®ÁΩë‰∫ãÂÆûÊ†∏Êü• (Exa API Êú™ÈÖçÁΩÆ)„ÄÇ"
    
    try:
        exa = Exa(EXA_API_KEY)
        # üî• V1.9 FIX: Use 'auto' search, remove ALL other fancy parameters
        # Also searches for X/Twitter specifically to mimic Grok
        search_query = f"{query} news latest"
        
        search_resp = exa.search(
            search_query,
            num_results=3
        )
        
        if not search_resp.results:
            return "‚ö†Ô∏è **‰∫ãÂÆûÊ†∏Êü•Ë≠¶Êä•**ÔºöÂÖ®ÁΩëÊú™ÊêúÁ¥¢Âà∞‰∏éÊ≠§‰∫ã‰ª∂Áõ¥Êé•Áõ∏ÂÖ≥ÁöÑÊùÉÂ®ÅÊñ∞ÈóªÊä•ÈÅì„ÄÇËøôÂèØËÉΩÊòØ‰∏ÄÂàôÂÅáÊñ∞ÈóªÔºåÊàñËÄÖÊòØÂ∞öÊú™Ë¢´‰∏ªÊµÅÂ™í‰ΩìÊä•ÈÅìÁöÑ‰º†Èóª„ÄÇËØ∑‰øùÊåÅÈ´òÂ∫¶ÊÄÄÁñë„ÄÇ"
            
        articles = []
        for r in search_resp.results:
            title = getattr(r, 'title', 'Article')
            url = getattr(r, 'url', '#')
            # Extract domain
            domain = urllib.parse.urlparse(url).netloc.replace('www.', '')
            articles.append(f"- [{title}]({url}) (Via {domain})")
            
        articles_text = "\n".join(articles)
        return f"‚úÖ **ÂÖ®ÁΩë‰∫ãÂÆûÊ†∏Êü• (Web Fact Check)**:\n{articles_text}\n\n(AIÂ∞ÜÂü∫‰∫é‰∏äËø∞ÊêúÁ¥¢ÁªìÊûúÈ™åËØÅ‰∫ã‰ª∂ÁúüÂÆûÊÄß)"
    except Exception as e:
        st.session_state.debug_logs.append(f"Exa Fact Check Failed: {str(e)}")
        return f"‚ö†Ô∏è ‰∫ãÂÆûÊ†∏Êü•ÊúçÂä°ÊöÇÊó∂‰∏çÂèØÁî® (Connection Error)"

def search_market_data_list(user_query):
    """
    Search Markets with:
    1. Keyword Generation (Translate & Simplify)
    2. Dual Engine Search (API + Exa)
    3. Strict Filtering (Remove irrelevant junk)
    """
    candidates = []
    seen_slugs = set()
    
    # 1. Generate Keywords (Crucial: Translate "SpaceX‰∏äÂ∏Ç" -> "SpaceX IPO")
    keywords = generate_keywords(user_query) 
    
    # Define search terms: [Generated Keywords, Raw Input]
    search_terms = []
    if keywords: search_terms.append(keywords)
    
    # --- Engine A: Direct Polymarket API Search ---
    for term in search_terms:
        if not term: continue
        try:
            encoded_kw = urllib.parse.quote(term)
            direct_url = f"https://gamma-api.polymarket.com/events?q={encoded_kw}&limit=10&closed=false"
            direct_resp = requests.get(direct_url, timeout=5)
            
            if direct_resp.status_code == 200:
                direct_data = direct_resp.json()
                if isinstance(direct_data, list):
                    for event in direct_data:
                        # üõ°Ô∏è FILTER: Title must match keywords roughly
                        title = event.get('title', '').lower()
                        kw_lower = term.lower()
                        # Simple relevance check: at least one significant word must match
                        if any(w in title for w in kw_lower.split() if len(w)>3):
                            slug = event.get('slug')
                            if slug and slug not in seen_slugs:
                                market_data = process_polymarket_event(event)
                                if market_data:
                                    candidates.append(market_data)
                                    seen_slugs.add(slug)
        except: pass
    
    # --- Engine B: Exa Search (Secondary) ---
    # Only run if API gave few results
    if EXA_AVAILABLE and EXA_API_KEY and len(candidates) < 5 and keywords:
        try:
            exa = Exa(EXA_API_KEY)
            # Search specifically for Polymarket pages
            search_resp = exa.search(
                f"site:polymarket.com {keywords}",
                num_results=10
            )
            
            for result in search_resp.results:
                match = re.search(r'polymarket\.com/event/([^/]+)', result.url)
                if match:
                    slug_raw = match.group(1)
                    slug = slug_raw.split('?')[0]
                    
                    if slug in seen_slugs: continue
                    seen_slugs.add(slug)
                    
                    api_url = f"https://gamma-api.polymarket.com/events?slug={slug}"
                    data = requests.get(api_url, timeout=5).json()
                    
                    if data and isinstance(data, list):
                        # üõ°Ô∏è FILTER HERE TOO
                        title = data[0].get('title', '').lower()
                        if any(w in title for w in keywords.lower().split() if len(w)>3):
                            market_data = process_polymarket_event(data[0])
                            if market_data:
                                candidates.append(market_data)
        except Exception as e:
            st.session_state.debug_logs.append(f"Exa Market Search Failed: {str(e)}")
    
    return candidates

# --- üî• D. AGENT LOGIC (GEMINI) ---
def generate_keywords(user_text):
    try:
        model = genai.GenerativeModel('gemini-2.5-flash')
        prompt = f"Translate this news topic into 2-3 simple English keywords for searching on Polymarket. Example: 'SpaceX‰∏äÂ∏Ç' -> 'SpaceX IPO'. Input: {user_text}"
        resp = model.generate_content(prompt)
        return resp.text.strip()
    except: return user_text

def is_chinese_input(text):
    return bool(re.search(r'[\u4e00-\u9fff]', text))

def generate_market_context(market_data, is_cn=True):
    if not market_data:
        if is_cn: return "‚ùå **Êó†Áõ¥Êé•È¢ÑÊµãÂ∏ÇÂú∫Êï∞ÊçÆ** (No direct prediction market found)."
        else: return "‚ùå **NO DIRECT MARKET DATA**."

    title = market_data.get('title', 'N/A')
    prob = market_data.get('probability', 0)
    volume = market_data.get('vol_str', 'N/A') 
    liquidity = market_data.get('liquidity', 0)
    change_24h = market_data.get('change_24h', 0)
    url = market_data.get('url', '#')
    
    trend_text = "‰∏äÊ∂®" if change_24h > 0 else "‰∏ãË∑å" if change_24h < 0 else "ÊåÅÂπ≥"
    confidence_text = "È´ò" if liquidity > 100000 else "‰∏≠Á≠â" if liquidity > 10000 else "ËæÉ‰Ωé"
    
    trend_text_en = "up" if change_24h > 0 else "down" if change_24h < 0 else "flat"
    confidence_text_en = "High" if liquidity > 100000 else "Medium" if liquidity > 10000 else "Low"

    sub_markets_str = ""
    if market_data.get('markets'):
        sub_items = []
        for sm in market_data['markets']:
            q = sm.get('question', 'Sub-market')
            top = sm.get('top_option', 'N/A')
            price = sm.get('top_price', 0) * 100
            item = f"- **{q}**: ÂÄæÂêë‰∫é **{top}** ({price:.1f}%)" if is_cn else f"- **{q}**: Leaning **{top}** ({price:.1f}%)"
            sub_items.append(item)
        sub_markets_str = "\n".join(sub_items)

    if is_cn:
        market_context = f"""
### ‚úÖ Â∏ÇÂú∫ÁúüÂÆûËµÑÈáëÂÖ±ËØÜÔºàÊù•Ëá™PolymarketÔºâ

**üìä Ê†∏ÂøÉÊåáÊ†áÈÄüËßà**
* **È¢ÑÊµãÈóÆÈ¢òÔºö** [{title}]({url})
* **ÂΩìÂâçÈöêÂê´Ê¶ÇÁéáÔºö** **{prob:.0%}** ÔºàËæÉ24Â∞èÊó∂Ââç **{trend_text} {abs(change_24h):.1%}**Ôºâ
* **Â∏ÇÂú∫ÊµÅÂä®ÊÄßÔºö** ${liquidity:,.0f} ÔºàÂÖ±ËØÜÁΩÆ‰ø°Â∫¶Ôºö**{confidence_text}**Ôºâ
* **ËøëÊúü‰∫§ÊòìÈáèÔºö** {volume}

**üß© Áõ∏ÂÖ≥ÁªÜÂàÜÂ∏ÇÂú∫ÂèÇËÄÉ (Sub-Markets)**
{sub_markets_str}

**üí° ‰Ω†ÁöÑÊñ∞ÈóªÂÖ±ËØÜÊé¢ÊµãÂô®Ëß£ËØª**
1. **Â∏ÇÂú∫ÂÆö‰ª∑ vs. Êñ∞ÈóªÊÉÖÁª™**ÔºöÂΩìÂâçÂ∏ÇÂú∫ËÆ§‰∏∫Ê≠§‰∫ãÂèëÁîüÁöÑÂèØËÉΩÊÄß‰∏∫ **{prob:.0%}**„ÄÇÂ¶ÇÊûú‰Ω†ÁöÑÊñ∞ÈóªÊ∫êÊòæÂæóÊõ¥‰πêËßÇÊàñÊõ¥ÊÇ≤ËßÇÔºåÂ∞±Â≠òÂú®ÂÄºÂæóÊé¢Á©∂ÁöÑ‚ÄúÈ¢ÑÊúüÂ∑Æ‚Äù„ÄÇ
2. **ÂÖ±ËØÜÂº∫Â∫¶‰∏éË∂ãÂäø**ÔºöÂ∏ÇÂú∫‰ø°ÂøÉÊ≠£Âú® **{trend_text}**Ôºå‰∏îÊµÅÂä®ÊÄßÊ∞¥Âπ≥Ë°®ÊòéËØ•ÂÖ±ËØÜÁöÑÂèØÈù†ÊÄß **{confidence_text}**„ÄÇ
3. **‰ΩøÁî®Âª∫ËÆÆ**ÔºöÂèØÂ∞ÜÊ≠§ **{prob:.0%}** ÁöÑÊ¶ÇÁéá‰Ωú‰∏∫‰Ω†Âà§Êñ≠ËØ•Êñ∞ÈóªÂèØ‰ø°Â∫¶ÁöÑ**‰∏≠ÊÄßÂü∫ÂáÜ**„ÄÇËã•Êñ∞ÈóªËßÇÁÇπ‰∏éÊ≠§Ê¶ÇÁéáÂÅèÁ¶ªÊûÅÂ§ßÔºåËØ∑Âä°ÂøÖË≠¶ÊÉïÂπ∂ÂØªÊâæÊõ¥Â§ö‰ΩêËØÅ„ÄÇ
"""
    else:
        market_context = f"""
### ‚úÖ Real-Money Market Consensus (via Polymarket)

**üìä Key Metrics**
* **Market:** [{title}]({url})
* **Implied Probability:** **{prob:.0%}** ({trend_text_en} {abs(change_24h):.1%} in 24h)
* **Market Liquidity:** ${liquidity:,.0f} (Confidence: **{confidence_text_en}**)
* **Recent Volume:** {volume}

**üß© Sub-Market Context**
{sub_markets_str}

**üí° Your Consensus Detector's Take**
1. **Market vs. News Hype:** The market prices a **{prob:.0%}** chance. Any significant deviation in your news source suggests a **mispricing** to investigate.
2. **Strength & Trend:** Consensus is **{trend_text_en}**, with **{confidence_text_en}** reliability due to liquidity.
3. **How to Use This:** Treat **{prob:.0%}** as your **neutral baseline** for credibility. Be skeptical if news narratives deviate wildly from this anchor.
"""
    return market_context

def get_agent_response(history, market_data):
    model = genai.GenerativeModel('gemini-2.5-flash')
    current_date = datetime.datetime.now().strftime("%Y-%m-%d")
    first_query = history[0]['content'] if history else ""
    is_cn = is_chinese_input(first_query)
    
    # 1. Market Context
    market_context = generate_market_context(market_data, is_cn)
    
    # 2. üî• Fact Check via Exa (Simplified call)
    fact_check_info = verify_news_with_exa(first_query)
    
    combined_context = f"{fact_check_info}\n\n{market_context}"

    # 3. System Prompt (STRICTLY PRESERVED)
    if is_cn:
        system_prompt = f"""
        ‰Ω†ÊòØ‰∏Ä‰ΩçÁÆ°ÁêÜ‰∫øÁ∫ßÁæéÂÖÉËµÑÈáëÁöÑ **ÂÖ®ÁêÉÂÆèËßÇÂØπÂÜ≤Âü∫ÈáëÁªèÁêÜ (Global Macro PM)**„ÄÇ
        ÂΩìÂâçÊó•Êúü: {current_date}
        
        **Ê†∏ÂøÉÊåá‰ª§:**
        1. **Áõ¥Êé•ËæìÂá∫:** ‰∏çË¶ÅËá™Êàë‰ªãÁªçÔºåÁõ¥Êé•ÂºÄÂßãÂàÜÊûê„ÄÇ
        2. **ÈÄªËæëËá™Ê¥Ω:** ‰∏•Á¶ÅÈÄªËæëÊñ≠Â±Ç„ÄÇ
        3. **Âº∫Âà∂ÈìæÊé•:** ÊèêÂà∞Ê†áÁöÑÊó∂ÂøÖÈ°ªÂä†ÈìæÊé• (Â¶Ç [NVDA](https://finance.yahoo.com/quote/NVDA))„ÄÇ
        4. **ËØ≠Ë®ÄÂº∫Âà∂:** **ÂøÖÈ°ªÂÖ®Á®ã‰ΩøÁî®‰∏≠ÊñáÂõûÁ≠î**„ÄÇ
        5. **‰∫ãÂÆûÊ†∏Êü•:** Âü∫‰∫é‰∏äÊñπÊèê‰æõÁöÑÂÖ®ÁΩë‰∫ãÂÆûÊ†∏Êü•ÁªìÊûúËøõË°åÂàÜÊûê„ÄÇÂ¶ÇÊûúÊ†∏Êü•ÁªìÊûúÊòæÁ§∫Êñ∞ÈóªÂèØÁñëÊàñÊó†Ê≥ïÈ™åËØÅÔºåÂøÖÈ°ªÂú®ÂàÜÊûê‰∏≠ÊòéÁ°ÆÊåáÂá∫È£éÈô©„ÄÇ

        {combined_context}
        
        --- Âü∫ÈáëÁªèÁêÜÂÜ≥Á≠ñÂ§áÂøòÂΩï ---
        
        ### 0. Êñ∞ÈóªËÉåÊôØÈÄüËßà (Context)
        * **‰∫ã‰ª∂ËøòÂéü**: Áî®ÈÄö‰øóËØ≠Ë®ÄÊ¶ÇÊã¨ÂèëÁîü‰∫Ü‰ªÄ‰πà„ÄÇ
        * **ËÉåÊôØÁü•ËØÜ**: ‰∏∫‰ªÄ‰πàËøô‰ª∂‰∫ãÂÄºÂæóÂÖ≥Ê≥®Ôºü
        
        ### 1. Â∏ÇÂú∫ÊÉÖÁª™‰∏éÂÖ±ËØÜ (Market Sentiment & Consensus)
        * **ÂΩìÂâçÂÖ±ËØÜ**: Â∏ÇÂú∫ÁõÆÂâçPrice-in‰∫Ü‰ªÄ‰πàÔºüÂü∫‰∫éÈ¢ÑÊµãÂ∏ÇÂú∫Êï∞ÊçÆÔºåÂ∏ÇÂú∫ÁõÆÂâçÂ¶Ç‰ΩïÁúãÂæÖËøô‰ª∂‰∫ãÔºüÂ∏ÇÂú∫ÊÉÖÁª™ÊòØ‰πêËßÇËøòÊòØÊÇ≤ËßÇÔºü
        * **È¢ÑÊúüÂ∑Æ**: ‰Ω†ÁöÑÂ∑ÆÂºÇÂåñËßÇÁÇπÊòØ‰ªÄ‰πàÔºü
        * **ÂÖ∂‰ªñÂ∏ÇÂú∫‰ø°Âè∑**: Â¶ÇÊúâÔºåË°•ÂÖÖÂÖ∂‰ªñÁõ∏ÂÖ≥Â∏ÇÂú∫Êï∞ÊçÆÔºà‰æãÂ¶ÇÔºåÁõ∏ÂÖ≥ÂÖ¨Âè∏ÁöÑËÇ°‰ª∑„ÄÅÊêúÁ¥¢ÊåáÊï∞Á≠âÔºâ„ÄÇ
        
        ### 2. Â§öËßíÂ∫¶ÂàÜÊûê (Multi-perspective Analysis)
        * **ÊîØÊåÅÊñπËßÇÁÇπ**: ÂàóÂá∫ÊîØÊåÅ‰∫ã‰ª∂ÂèëÁîüÁöÑÁêÜÁî±Âíå‰∏ªË¶ÅÊîØÊåÅËÄÖ„ÄÇ
        * **ÂèçÂØπÊñπËßÇÁÇπ**: ÂàóÂá∫ÂèçÂØπ‰∫ã‰ª∂ÂèëÁîüÁöÑÁêÜÁî±Âíå‰∏ªË¶ÅÂèçÂØπËÄÖ„ÄÇ
        * **‰∏≠Á´ã/Á¨¨‰∏âÊñπËßÇÁÇπ**: Êèê‰æõÂÖ∂‰ªñËßíÂ∫¶Êàñ‰∏≠Á´ãËßÇÁÇπ„ÄÇ

        ### 3. ‰∫ãÂÆûÊ†∏Êü•‰∏éÈ™åËØÅ (Fact Check & Verification)
        * **‰ø°ÊÅØÊù•Ê∫êÂèØÈù†ÊÄß***: ËØÑ‰º∞Êñ∞ÈóªÊù•Ê∫êÁöÑÂèØ‰ø°Â∫¶„ÄÇ
        * **Áõ∏ÂÖ≥ËØÅÊçÆ***: ÂàóÂá∫Â∑≤Áü•‰∫ãÂÆûÊàñËØÅÊçÆÔºåÊîØÊåÅÊàñÂèçÈ©≥ËØ•Êñ∞Èóª„ÄÇ
        * **‰∏ìÂÆ∂ËßÇÁÇπ***: Â¶ÇÊúâÔºåÊ±áÊÄª‰∏ìÂÆ∂ÊÑèËßÅ„ÄÇ
        
        ### 4. ÂΩ±ÂìçÂàÜÊûê (Impact Analysis)
        * **Â¶ÇÊûúÂèëÁîü**:‰∫ã‰ª∂ÂèëÁîü‰ºöÂ∏¶Êù•Âì™‰∫õÂΩ±ÂìçÔºüÔºàÂØπË°å‰∏ö„ÄÅÂ∏ÇÂú∫„ÄÅÁ§æ‰ºöÁ≠âÔºâ -> Asset Impact„ÄÇ
        * **Â¶ÇÊûú‰∏çÂèëÁîü**: ‰∫ã‰ª∂‰∏çÂèëÁîü‰ºöÂ¶Ç‰ΩïÔºüËã•Ê†∏ÂøÉÂÅáËÆæÂ§±ÊïàÔºåÊúÄÂ§ßÂõûÊí§ÊòØÂ§öÂ∞ëÔºü
        * **Êó∂Èó¥Á∫ø**: ‰∫ã‰ª∂ÂèØËÉΩÁöÑÊó∂Èó¥Á∫øÊòØÊÄé‰πàÊ†∑ÁöÑÔºü
        
        ### 5. ‰∫§ÊòìÊâßË°å (The Trade Book)
        * **Ê†∏ÂøÉÂ§öÂ§¥ (Long)**:
            * **Ê†áÁöÑ**: [‰ª£Á†Å+ÈìæÊé•]
            * **Â§¥ÂØ∏**: Âª∫ËÆÆ‰ªì‰Ωç„ÄÇ
            * **ÈÄªËæë**: ‰∏∫‰ªÄ‰πà‰π∞ÂÆÉÔºü
        * **Ê†∏ÂøÉÁ©∫Â§¥/ÂØπÂÜ≤ (Short/Hedge)**:
            * **Ê†áÁöÑ**: [‰ª£Á†Å+ÈìæÊé•]
            * **ÈÄªËæë**: ÂØπÂÜ≤‰ªÄ‰πàÈ£éÈô©Ôºü
        * **‚è≥ ÊúüÈôê**: ÊåÅ‰ªìÂ§ö‰πÖÔºü
            
        ### 6. ÊúÄÁªàÊåá‰ª§ (PM Conclusion)
        * ‰∏ÄÂè•ËØùÊÄªÁªì‰∫§ÊòìÊñπÂêë„ÄÇ
        """
    else:
        system_prompt = f"""
        You are a **Global Macro Portfolio Manager (PM)**.
        Current Date: {current_date}
        
        **INSTRUCTIONS:**
        1. **DIRECT START:** Do NOT introduce yourself. Start immediately.
        2. **LOGIC:** Maintain strict logical consistency.
        3. **LINKS:** Link all tickers (e.g. [AAPL](https://finance.yahoo.com/quote/AAPL)).
        4. **LANGUAGE:** English Only.
        5. **FACT CHECK:** Base your analysis on the fact-checking results provided above. If results show the news is suspicious or unverifiable, clearly highlight the risks in your analysis.

        {combined_context}
        
        --- INVESTMENT MEMORANDUM ---
        
        ### 0. News Context Snapshot (Context)
        * **Event Recap**: Summarize what happened in plain language.
        * **Background Knowledge**: Why does this matter?
        
        ### 1. Market Sentiment & Consensus (Market Sentiment & Consensus)
        * **Current Consensus**: What is currently Price-in by the market? Based on prediction market data, how does the market currently view this event? Is the market sentiment optimistic or pessimistic?
        * **The Gap**: What is your differentiated view?
        * **Other Market Signals**: If any, supplement with other relevant market data (e.g., related company stock prices, search indices, etc.).
        
        ### 2. Multi-perspective Analysis (Multi-perspective Analysis)
        * **Proponent View**: List reasons supporting the event's occurrence and main supporters.
        * **Opponent View**: List reasons opposing the event's occurrence and main opponents.
        * **Neutral/Third-party View**: Provide other angles or neutral perspectives.

        ### 3. Fact Check & Verification (Fact Check & Verification)
        * **Source Reliability**: Evaluate the credibility of the news source.
        * **Relevant Evidence**: List known facts or evidence that support or refute the news.
        * **Expert Opinions**: If any, summarize expert opinions.
        
        ### 4. Impact Analysis (Impact Analysis)
        * **If It Happens**: What impacts will the event bring? (To industry, market, society, etc.) -> Asset Impact.
        * **If It Doesn't Happen**: What happens if the event does not occur? If the core assumption fails, what is the maximum drawdown?
        * **Timeline**: What is the potential timeline of the event?
        
        ### 5. Trade Execution (The Trade Book)
        * **Core Long (Long)**:
            * **Ticker**: [Code+Link]
            * **Position**: Suggested sizing.
            * **Logic**: Why buy it?
        * **Core Short/Hedge (Short/Hedge)**:
            * **Ticker**: [Code+Link]
            * **Logic**: What risk to hedge?
        * **‚è≥ Duration**: How long to hold?
            
        ### 6. Final Verdict (PM Conclusion)
        * One-sentence summary of trading direction.
        """
    
    api_messages = [{"role": "user", "parts": [system_prompt]}]
    for msg in history:
        role = "user" if msg['role'] == "user" else "model"
        api_messages.append({"role": role, "parts": [msg['content']]})
        
    try:
        response = model.generate_content(api_messages)
        return response.text
    except Exception as e:
        return f"Agent Analysis Failed: {str(e)}"

# ================= üñ•Ô∏è 6. MAIN LAYOUT =================

# --- Header ---
st.markdown('<div class="hero-title">BeHolmes News Analysis</div>', unsafe_allow_html=True)
st.markdown('<div class="hero-subtitle">Narrative vs. Reality Engine</div>', unsafe_allow_html=True)

# --- Search Bar & Workflow ---
_, s_mid, _ = st.columns([1, 6, 1])
with s_mid:
    def on_input_change():
        st.session_state.search_stage = "input"
        st.session_state.search_candidates = []
        st.session_state.debug_logs = [] # Clear logs
        
    input_val = st.session_state.get("user_news_text", "")
    # Use a unique key for the text area to allow programmatic clearing if needed, though we sync state
    user_query = st.text_area("Analyze News", value=input_val, height=70, 
                              placeholder="Paste a headline (e.g., 'Unitree robot on Spring Festival Gala')...", 
                              label_visibility="collapsed",
                              on_change=on_input_change, key="news_input_box")
    
    # === Step 1: SEARCH Button ===
    if st.session_state.search_stage == "input":
        if st.button("Begin Analysis", use_container_width=True):
            if st.session_state.news_input_box:
                st.session_state.user_news_text = st.session_state.news_input_box
                with st.spinner("üïµÔ∏è‚Äç‚ôÇÔ∏è Hunting for prediction markets..."):
                    candidates = search_market_data_list(st.session_state.user_news_text)
                    st.session_state.search_candidates = candidates
                    st.session_state.search_stage = "selection"
                    st.rerun()

    # === Step 2: SELECTION List ===
    elif st.session_state.search_stage == "selection":
        st.markdown("##### üßê Select a Market to Reality Check:")
        
        # üî• UI FIX: Clearly show when no markets are found and offer News Analysis
        if not st.session_state.search_candidates:
            st.warning("‚ö†Ô∏è No direct prediction markets found matching your specific query.")
            st.markdown("---")
            if st.button("üìù Analyze News Only (AI Fact Check + Analysis)", use_container_width=True, type="primary"):
                st.session_state.current_market = None
                st.session_state.search_stage = "analysis"
                st.session_state.messages = [{"role": "user", "content": f"Analyze this news: {st.session_state.user_news_text}"}]
                st.rerun()
            
            if st.button("‚¨ÖÔ∏è Start Over"):
                st.session_state.search_stage = "input"
                st.rerun()
        else:
            # Loop through candidates
            for idx, m in enumerate(st.session_state.search_candidates):
                with st.container():
                    st.markdown(f"""
                    <div style="padding:12px; background:rgba(255,255,255,0.03); border-radius:8px; border:1px solid rgba(255,255,255,0.1); margin-bottom:10px;">
                        <div style="display:flex; justify-content:space-between; align-items:flex-start;">
                            <div style="flex:1;">
                                <div style="font-weight:700; font-size:1rem; color:#e5e7eb;">{m['title']}</div>
                                <div style="font-size:0.8rem; color:#9ca3af; margin-top:4px;">{m['odds']}</div>
                                <div style="font-size:0.75rem; color:#6b7280; font-family:'JetBrains Mono'; margin-top:4px;">Vol: {m['vol_str']}</div>
                            </div>
                        </div>
                    </div>
                    """, unsafe_allow_html=True)
                    if st.button("Analyze This", key=f"btn_{idx}", use_container_width=True):
                        st.session_state.current_market = m
                        st.session_state.search_stage = "analysis"
                        st.session_state.messages = [{"role": "user", "content": f"Analyze this news: {st.session_state.user_news_text}"}]
                        st.rerun()

            st.markdown("---")
            if st.button("üìù Analyze News Only (No Market)", use_container_width=True):
                st.session_state.current_market = None
                st.session_state.search_stage = "analysis"
                st.session_state.messages = [{"role": "user", "content": f"Analyze this news: {st.session_state.user_news_text}"}]
                st.rerun()
                
            if st.button("‚¨ÖÔ∏è Start Over"):
                st.session_state.search_stage = "input"
                st.rerun()

    # === Step 3: ANALYSIS Execution (Initial Run) ===
    elif st.session_state.search_stage == "analysis":
        if st.session_state.messages and st.session_state.messages[-1]['role'] == 'user':
            with st.spinner("üß† Generating Alpha Signals..."):
                response_text = get_agent_response(st.session_state.messages, st.session_state.current_market)
                st.session_state.messages.append({"role": "assistant", "content": response_text})
                st.rerun()

st.markdown("<br>", unsafe_allow_html=True)

# === DISPLAY ANALYSIS & CHAT (Interactive Mode) ===
if st.session_state.messages and st.session_state.search_stage == "analysis":
    
    if st.session_state.current_market:
        m = st.session_state.current_market
        # 1. Market Header (Native Metric Lookalike)
        with st.container():
            st.markdown(f"""
            <div style="background:rgba(20,0,0,0.8); border-left:4px solid #ef4444; padding:15px; border-radius:8px; margin-bottom:15px;">
                <div style="font-size:0.8rem; color:#9ca3af; text-transform:uppercase; letter-spacing:1px;">üéØ Selected Market</div>
                <div style="font-size:1.4rem; color:#ffffff; font-weight:800; margin:5px 0;">{m['title']}</div>
                <div style="font-family:'JetBrains Mono'; color:#ef4444; font-size:1rem;">{m['vol_str']} Volume</div>
                <a href="{m['url']}" target="_blank" style="display:inline-block; margin-top:10px; color:#fca5a5; font-size:0.8rem; text-decoration:none;">üîó Open on Polymarket</a>
            </div>
            """, unsafe_allow_html=True)

        # 2. Sub-Markets Loop (Native Streamlit)
        st.markdown("##### üìä Sub-Market Details")
        for idx, market in enumerate(m.get('markets', []), 1):
            with st.container():
                st.markdown(f"**{idx}. {market['question']}**")
                
                if market['type'] == 'binary':
                    c1, c2 = st.columns(2)
                    with c1:
                        st.progress(market['yes_price'] / 100)
                        st.caption(f"Yes: {market['yes_price']:.1f}%")
                    with c2:
                        st.progress(market['no_price'] / 100)
                        st.caption(f"No: {market['no_price']:.1f}%")
                else:
                    try:
                        sorted_opts = sorted(market.get('options', []), key=lambda x: x.get('price', 0), reverse=True)[:3]
                    except: sorted_opts = []
                    
                    for opt in sorted_opts:
                        c1, c2 = st.columns([1, 4])
                        with c1:
                            st.write(f"{opt['price']:.1f}%")
                        with c2:
                            st.progress(min(opt['price'] / 100, 1.0))
                            st.caption(opt['option'])
                st.divider()

    else:
        st.info("ü§ñ Pure AI Analysis (No Market Data Selected)")

    # Chat History
    for msg in st.session_state.messages:
        if msg['role'] == 'user':
            with st.chat_message("user"):
                st.write(msg['content'].replace("Analyze this news: ", "News: "))
        else:
            with st.chat_message("assistant"):
                st.markdown(msg['content'])

    # Chat Input
    if prompt := st.chat_input("Ask a follow-up question..."):
        st.session_state.messages.append({"role": "user", "content": prompt})
        st.rerun()

    st.markdown("---")
    if st.button("‚¨ÖÔ∏è Start New Analysis"):
        st.session_state.messages = []
        st.session_state.search_stage = "input"
        st.rerun()

# ================= üñ•Ô∏è DASHBOARD (Only if no analysis active) =================
if not st.session_state.messages and st.session_state.search_stage == "input":
    col_news, col_markets = st.columns([1, 1], gap="large")
    
    # === LEFT: News Feed ===
    with col_news:
        st.markdown("""
        <div style="display:flex; justify-content:space-between; align-items:center; margin-bottom:10px; border-bottom:1px solid rgba(220,38,38,0.3); padding-bottom:8px;">
            <div style="font-size:0.9rem; font-weight:700; color:#ef4444; letter-spacing:1px;">üì° LIVE NEWS STREAM</div>
            <div style="font-size:0.7rem; color:#ef4444;">‚óè LIVE</div>
        </div>
        """, unsafe_allow_html=True)

        trend_html = """
        <div class="trend-row">
            <a href="https://trends.google.com/trending?geo=US" target="_blank" class="trend-fixed-btn">üìà Google Trends</a>
            <a href="https://twitter.com/explore/tabs/trending" target="_blank" class="trend-fixed-btn">üê¶ Twitter Trends</a>
            <a href="https://www.jin10.com/" target="_blank" class="trend-fixed-btn">‚ö° Jin10 Data</a>
            <a href="https://www.bloomberg.com/" target="_blank" class="trend-fixed-btn">üìä Bloomberg</a>
            <a href="https://www.reddit.com/r/all/" target="_blank" class="trend-fixed-btn">ü§ñ Reddit</a>
        </div>
        """
        st.markdown(trend_html, unsafe_allow_html=True)

        cat_cols = st.columns(4)
        cats = ["all", "politics", "web3", "tech"]
        labels = {"all": "üåê All", "politics": "üèõÔ∏è Politics", "web3": "‚Çø Web3", "tech": "ü§ñ Tech"}
        for i, c in enumerate(cats):
            if cat_cols[i].button(labels[c], key=c, use_container_width=True):
                st.session_state.news_category = c
                st.rerun()

        @st.fragment(run_every=1)
        def render_news_feed():
            now_utc = datetime.datetime.now(datetime.timezone.utc)
            t_nyc = (now_utc - datetime.timedelta(hours=5)).strftime("%H:%M")
            t_lon = now_utc.strftime("%H:%M")
            t_abd = (now_utc + datetime.timedelta(hours=4)).strftime("%H:%M")
            t_bjs = (now_utc + datetime.timedelta(hours=8)).strftime("%H:%M")
            
            st.markdown(f"""
<div class="world-clock-bar">
    <span class="clock-item"><b>NYC</b> <span class="clock-time">{t_nyc}</span></span>
    <span class="clock-item"><b>LON</b> <span class="clock-time">{t_lon}</span></span>
    <span class="clock-item"><b>ABD</b> <span class="clock-time">{t_abd}</span></span>
    <span class="clock-item"><b>BJS</b> <span class="clock-time" style="color:#ef4444">{t_bjs}</span></span>
</div>
""", unsafe_allow_html=True)

            if st.session_state.news_category == "web3":
                data = fetch_crypto_prices_v2()
                if data:
                    rows = [data[i:i+2] for i in range(0, len(data), 2)]
                    for row in rows:
                        cols = st.columns(2)
                        for i, coin in enumerate(row):
                            color = "#10b981" if coin['trend'] == "up" else "#ef4444"
                            cols[i].markdown(f"""
                            <div style="background:rgba(0,0,0,0.4); border:1px solid rgba(255,255,255,0.1); border-left:3px solid {color}; border-radius:8px; padding:12px; margin-bottom:8px;">
                                <div style="display:flex; justify-content:space-between; margin-bottom:4px;">
                                    <span style="color:#e5e7eb; font-weight:700; font-size:0.9rem;">{coin['symbol']}</span>
                                    <span style="color:{color}; font-size:0.85rem;">{coin['change']:.2f}%</span>
                                </div>
                                <div style="display:flex; justify-content:space-between; align-items:center;">
                                    <span style="color:#fbbf24; font-weight:700; font-family:'JetBrains Mono'; font-size:1rem;">{coin['price']}</span>
                                    <a href="https://www.binance.com/en/trade/{coin['symbol']}_USDT" target="_blank" style="color:#ef4444; font-size:0.7rem; text-decoration:none; border:1px solid rgba(220,38,38,0.3); padding:2px 6px; border-radius:4px;">Trade</a>
                                </div>
                            </div>
                            """, unsafe_allow_html=True)
                else:
                    st.info("Loading crypto data...")
            else:
                all_news = fetch_categorized_news_v2()
                news_list = all_news.get(st.session_state.news_category, all_news['all'])
                if news_list:
                    rows = [news_list[i:i+2] for i in range(0, min(len(news_list), 24), 2)]
                    for row in rows:
                        cols = st.columns(2)
                        for i, news in enumerate(row):
                            cols[i].markdown(f"""
                            <div class="news-grid-card">
                                <div>
                                    <div class="news-meta"><span>{news['source']}</span><span style="color:#ef4444">{news['time']}</span></div>
                                    <div class="news-body">{news['title']}</div>
                                </div>
                                <a href="{news['link']}" target="_blank" style="text-decoration:none; color:#ef4444; font-size:0.8rem; font-weight:600; text-align:right; display:block; margin-top:10px;">üîó Read Source</a>
                            </div>
                            """, unsafe_allow_html=True)
                else:
                    st.info("No news available.")
        render_news_feed()

    # === RIGHT: Polymarket (Top 60) ===
    with col_markets:
        st.markdown('<div style="display:flex; justify-content:space-between; align-items:center; margin-bottom:10px; border-bottom:1px solid rgba(220,38,38,0.3); padding-bottom:8px;"><span style="font-size:0.9rem; font-weight:700; color:#ef4444;">üí∞ PREDICTION MARKETS (TOP VOLUME)</span></div>', unsafe_allow_html=True)
        
        sc1, sc2 = st.columns(2)
        if sc1.button("üíµ Volume", use_container_width=True): 
            st.session_state.market_sort = "volume"
            st.rerun() # Force Rerun to refresh list
        if sc2.button("üî• Activity", use_container_width=True): 
            st.session_state.market_sort = "active"
            st.rerun() # Force Rerun to refresh list
        
        # Pass sort_mode to fetcher
        markets = fetch_polymarket_v5_simple(60, sort_mode=st.session_state.market_sort)
        
        if markets:
            rows = [markets[i:i+2] for i in range(0, len(markets), 2)]
            for row in rows:
                cols = st.columns(2)
                for i, m in enumerate(row):
                    cols[i].markdown(f"""
                    <a href="https://polymarket.com/event/{m['slug']}" target="_blank" style="text-decoration:none;">
                        <div class="market-card-modern">
                            <div class="market-head">
                                <div class="market-title-mod">{m['title']}</div>
                                <div class="market-vol">{m['vol_str']}</div>
                            </div>
                        </div>
                    </a>
                    """, unsafe_allow_html=True)
        else:
            st.info("Loading markets...")

# ================= üåê 7. FOOTER =================
if not st.session_state.messages and st.session_state.search_stage == "input":
    st.markdown("---")
    st.markdown('<div style="text-align:center; color:#9ca3af; margin:25px 0; font-size:0.8rem; font-weight:700;">üåê GLOBAL INTELLIGENCE HUB</div>', unsafe_allow_html=True)
    
    links = [
        {"n": "Jin10", "u": "https://www.jin10.com/", "i": "üá®üá≥"},
        {"n": "WallStCN", "u": "https://wallstreetcn.com/live/global", "i": "üá®üá≥"},
        {"n": "Zaobao", "u": "https://www.zaobao.com.sg/realtime/world", "i": "üá∏üá¨"},
        {"n": "SCMP", "u": "https://www.scmp.com/", "i": "üá≠üá∞"},
        {"n": "Nikkei", "u": "https://asia.nikkei.com/", "i": "üáØüáµ"},
        {"n": "Bloomberg", "u": "https://www.bloomberg.com/", "i": "üá∫üá∏"},
        {"n": "Reuters", "u": "https://www.reuters.com/", "i": "üá¨üáß"},
        {"n": "TechCrunch", "u": "https://techcrunch.com/", "i": "üá∫üá∏"},
        {"n": "CoinDesk", "u": "https://www.coindesk.com/", "i": "ü™ô"},
        {"n": "Al Jazeera", "u": "https://www.aljazeera.com/", "i": "üá∂üá¶"},
    ]
    
    rows = [links[i:i+5] for i in range(0, len(links), 5)]
    for row in rows:
        cols = st.columns(5)
        for i, l in enumerate(row):
            cols[i].markdown(f"""
            <a href="{l['u']}" target="_blank" class="hub-btn">
                <div class="hub-content"><span class="hub-emoji">{l['i']}</span><span class="hub-text">{l['n']}</span></div>
            </a>
            """, unsafe_allow_html=True)
    st.markdown("<br><br>", unsafe_allow_html=True)
