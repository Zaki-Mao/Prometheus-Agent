import streamlit as st
import requests
import json
import google.generativeai as genai
from google.generativeai.types import HarmCategory, HarmBlockThreshold
import re
import time
import datetime
import random
import urllib.parse
import html
import textwrap

# -----------------------------------------------------------------------------
# 0. DEPENDENCY CHECK
# -----------------------------------------------------------------------------
try:
    import feedparser
except ImportError:
    st.error("âŒ ç¼ºå°‘å¿…è¦ç»„ä»¶ï¼šfeedparserã€‚è¯·åœ¨ requirements.txt ä¸­æ·»åŠ  'feedparser' æˆ–è¿è¡Œ pip install feedparserã€‚")
    st.stop()

# ================= ğŸ” 1. KEY MANAGEMENT =================
try:
    EXA_API_KEY = st.secrets.get("EXA_API_KEY", None)
    GOOGLE_API_KEY = st.secrets.get("GOOGLE_API_KEY", None)
    NEWS_API_KEY = st.secrets.get("NEWS_API_KEY", None)
    KEYS_LOADED = True
except:
    EXA_API_KEY = None
    GOOGLE_API_KEY = None
    NEWS_API_KEY = None
    KEYS_LOADED = False

if GOOGLE_API_KEY:
    genai.configure(api_key=GOOGLE_API_KEY)

# ================= ğŸ› ï¸ DEPENDENCY CHECK (EXA) =================
try:
    from exa_py import Exa
    EXA_AVAILABLE = True
except ImportError:
    EXA_AVAILABLE = False

# ================= ğŸ•µï¸â€â™‚ï¸ 2. SYSTEM CONFIGURATION =================
st.set_page_config(
    page_title="Be Holmes | News Analysis",
    page_icon="ğŸ•µï¸â€â™‚ï¸",
    layout="wide",
    initial_sidebar_state="collapsed"
)

# ================= ğŸ§  3. STATE MANAGEMENT =================
default_state = {
    "messages": [],
    "current_market": None,
    "search_candidates": [],     # Stores list of found markets
    "search_stage": "input",     # input -> selection -> analysis
    "user_news_text": "",
    "is_processing": False,
    "last_user_input": "",
    "news_category": "all",
    "market_sort": "volume",
    "debug_logs": []             # Store debug info
}

for key, value in default_state.items():
    if key not in st.session_state:
        st.session_state[key] = value

# ================= ğŸ¨ 4. UI THEME (MOBILE OPTIMIZED VERSION) =================
st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;600;900&family=Plus+Jakarta+Sans:wght@400;700&display=swap');
    @import url('https://fonts.googleapis.com/css2?family=JetBrains+Mono:wght@400;700&display=swap');

    /* === Global Background === */
    .stApp {
        background-image: linear-gradient(rgba(0, 0, 0, 0.92), rgba(20, 0, 0, 0.96)), 
                          url('https://upload.cc/i1/2026/01/20/s8pvXA.jpg');
        background-size: cover;
        background-position: center;
        background-attachment: fixed;
        font-family: 'Inter', sans-serif;
    }
    
    /* === ğŸ“± Mobile Layout Optimization === */
    /* Reduce padding on mobile devices to maximize screen real estate */
    .block-container {
        padding-top: 2rem !important;
        padding-bottom: 4rem !important;
        padding-left: 1rem !important;
        padding-right: 1rem !important;
    }

    /* === Hero Title (Responsive) === */
    .hero-title {
        font-family: 'Inter', sans-serif;
        font-weight: 700;
        font-size: 3.5rem; 
        color: #ffffff;
        text-align: center;
        letter-spacing: -2px;
        margin-bottom: 5px;
        padding-top: 2vh;
        text-shadow: 0 0 30px rgba(220, 38, 38, 0.6);
        line-height: 1.1;
    }
    .hero-subtitle {
        font-family: 'Plus Jakarta Sans', sans-serif;
        font-size: 1rem;
        color: #9ca3af; 
        text-align: center;
        margin-bottom: 25px;
        font-weight: 400;
    }
    
    /* Adjust Title size for mobile */
    @media (max-width: 600px) {
        .hero-title { font-size: 2.2rem; letter-spacing: -1px; }
        .hero-subtitle { font-size: 0.9rem; margin-bottom: 15px; }
    }

    /* === Fixed Time Zone Bar (Responsive) === */
    .world-clock-bar {
        display: flex; 
        justify-content: space-between; 
        background: rgba(0,0,0,0.5); 
        padding: 8px 10px; 
        border-radius: 6px; 
        margin-bottom: 15px;
        border: 1px solid rgba(220, 38, 38, 0.2);
        font-family: 'JetBrains Mono', monospace;
        flex-wrap: wrap; /* Wrap content on small screens */
        gap: 5px;
    }
    .clock-item { font-size: 0.7rem; color: #9ca3af; display: flex; align-items: center; gap: 4px; }
    .clock-item b { color: #e5e7eb; font-weight: 700; }
    .clock-time { color: #f87171; }

    /* === Buttons === */
    div.stButton > button {
        background: linear-gradient(90deg, #991b1b 0%, #7f1d1d 100%) !important;
        color: white !important;
        border: 1px solid #b91c1c !important;
        border-radius: 8px !important;
        font-weight: 600 !important;
        transition: all 0.3s !important;
    }
    div.stButton > button:hover {
        background: linear-gradient(90deg, #dc2626 0%, #b91c1c 100%) !important;
        box-shadow: 0 0 15px rgba(220, 38, 38, 0.6) !important;
        border-color: #fca5a5 !important;
        transform: scale(1.02) !important;
    }

    /* === News Cards (Responsive) === */
    .news-grid-card {
        background: rgba(20, 0, 0, 0.6);
        border: 1px solid rgba(255, 255, 255, 0.05);
        border-left: 3px solid #dc2626;
        border-radius: 8px;
        padding: 15px;
        height: 100%;
        min-height: 140px;
        display: flex;
        flex-direction: column;
        justify-content: space-between;
        transition: all 0.3s ease-in-out;
    }
    /* Mobile: Allow height to grow based on content */
    @media (max-width: 600px) {
        .news-grid-card { min-height: auto; margin-bottom: 10px; }
    }
    .news-grid-card:hover {
        background: rgba(40, 0, 0, 0.8);
        border-color: #ef4444;
        box-shadow: 0 0 15px rgba(220, 38, 38, 0.2);
        transform: translateY(-2px);
    }
    .news-meta {
        font-size: 0.7rem;
        color: #fca5a5;
        font-weight: 600;
        margin-bottom: 8px;
        display: flex;
        justify-content: space-between;
    }
    .news-body {
        font-size: 0.9rem;
        color: #e5e7eb;
        line-height: 1.4;
        font-weight: 500;
        margin-bottom: 15px;
        display: -webkit-box;
        -webkit-line-clamp: 3;
        -webkit-box-orient: vertical;
        overflow: hidden;
    }
    
    /* === Market Card Modern (Responsive) === */
    .market-card-modern {
        background: rgba(255, 255, 255, 0.02);
        border: 1px solid rgba(255, 255, 255, 0.1);
        border-radius: 8px;
        padding: 12px;
        margin-bottom: 10px;
        transition: all 0.2s;
        cursor: pointer;
    }
    .market-card-modern:hover {
        border-color: #ef4444;
        background: rgba(40, 0, 0, 0.3);
        transform: translateY(-2px);
    }
    .market-head {
        display: flex;
        justify-content: space-between;
        align-items: flex-start;
        margin-bottom: 10px;
    }
    /* Mobile: Stack title and volume if needed */
    @media (max-width: 600px) {
        .market-head { flex-direction: column; }
        .market-title-mod { margin-bottom: 5px; }
    }
    .market-title-mod {
        font-size: 0.85rem;
        color: #e5e7eb;
        font-weight: 600;
        line-height: 1.3;
        flex: 1;
        margin-right: 10px;
    }
    .market-vol {
        font-size: 0.7rem;
        color: #9ca3af;
        white-space: nowrap;
        background: rgba(255,255,255,0.05);
        padding: 2px 6px;
        border-radius: 4px;
        font-family: 'JetBrains Mono', monospace;
    }
    .outcome-row {
        display: flex;
        justify-content: space-between;
        gap: 10px;
    }
    .outcome-box {
        flex: 1;
        padding: 8px;
        border-radius: 6px;
        display: flex;
        justify-content: space-between;
        align-items: center;
        font-family: 'JetBrains Mono', monospace;
    }
    .outcome-box.yes { background: rgba(16, 185, 129, 0.1); border: 1px solid rgba(16, 185, 129, 0.2); }
    .outcome-box.no { background: rgba(239, 68, 68, 0.1); border: 1px solid rgba(239, 68, 68, 0.2); }
    .outcome-label { font-size: 0.75rem; font-weight: 600; }
    .outcome-price { font-size: 1rem; font-weight: 700; }
    .yes-color { color: #10b981; }
    .no-color { color: #ef4444; }

    /* === Input Area === */
    .stTextArea textarea {
        background-color: rgba(20, 0, 0, 0.6) !important;
        border: 1px solid #7f1d1d !important;
        color: white !important;
        border-radius: 12px !important;
        font-size: 1rem !important;
    }
    .stTextArea textarea:focus {
        border-color: #ef4444 !important;
        box-shadow: 0 0 10px rgba(220, 38, 38, 0.4) !important;
    }
    
    /* === Chat Input styling === */
    .stChatInput input {
        background-color: rgba(20, 0, 0, 0.6) !important;
        color: white !important;
        border: 1px solid #7f1d1d !important;
    }

    /* === Hub Button === */
    .hub-btn {
        display: flex;
        flex-direction: column;
        align-items: center;
        justify-content: center;
        width: 100%;
        height: 70px;
        background: rgba(255, 255, 255, 0.03);
        border: 1px solid rgba(255, 255, 255, 0.08);
        border-radius: 10px;
        text-align: center;
        text-decoration: none;
        transition: all 0.3s cubic-bezier(0.4, 0, 0.2, 1);
        backdrop-filter: blur(5px);
        margin-bottom: 10px;
        cursor: pointer;
    }
    .hub-btn:hover {
        background: rgba(40, 0, 0, 0.6);
        border-color: #ef4444;
        transform: translateY(-3px);
        box-shadow: 0 5px 15px rgba(220, 38, 38, 0.3);
    }
    .hub-content { display: flex; flex-direction: column; align-items: center; }
    .hub-emoji { font-size: 1.4rem; line-height: 1.2; margin-bottom: 4px; filter: grayscale(0.2); }
    .hub-btn:hover .hub-emoji { filter: grayscale(0); transform: scale(1.1); transition: transform 0.2s;}
    .hub-text { 
        font-family: 'Inter', sans-serif;
        font-size: 0.8rem; 
        color: #d1d5db; 
        font-weight: 600; 
        letter-spacing: 0.5px;
    }
    .hub-btn:hover .hub-text { color: #ffffff; }
    
    /* === Global Trends Buttons (Fixed & Responsive) === */
    .trend-row { 
        display: flex; 
        gap: 8px; 
        flex-wrap: wrap; 
        margin-bottom: 20px; 
        justify-content: flex-start; 
    }
    .trend-fixed-btn {
        background: rgba(220, 38, 38, 0.1);
        border: 1px solid rgba(220, 38, 38, 0.3);
        color: #fca5a5;
        padding: 6px 14px;
        border-radius: 6px;
        font-size: 0.8rem;
        font-weight: 600;
        text-decoration: none;
        display: flex;
        align-items: center;
        gap: 6px;
        transition: all 0.2s;
        white-space: nowrap; /* Prevent breaking inside button */
    }
    .trend-fixed-btn:hover {
        background: rgba(220, 38, 38, 0.4);
        color: white;
        border-color: #ef4444;
        transform: translateY(-2px);
    }
    
    /* Small screen tweaks */
    @media (max-width: 400px) {
        .trend-fixed-btn { font-size: 0.7rem; padding: 5px 10px; }
        .hub-text { font-size: 0.7rem; }
    }
    
    .ex-link {
        font-size: 0.7rem; color: #6b7280; text-decoration: none; margin-top: 5px; display: block; text-align: right;
    }
    .ex-link:hover { color: #ef4444; }
</style>
""", unsafe_allow_html=True)

# ================= ğŸ§  5. LOGIC CORE =================

# --- ğŸ”¥ A. Crypto Prices (Extended List) ---
@st.cache_data(ttl=60)
def fetch_crypto_prices_v2():
    symbols = [
        "BTCUSDT", "ETHUSDT", "SOLUSDT", "BNBUSDT", "XRPUSDT", 
        "DOGEUSDT", "ADAUSDT", "AVAXUSDT", "SHIBUSDT", "DOTUSDT", 
        "LINKUSDT", "TRXUSDT", "MATICUSDT", "LTCUSDT", "BCHUSDT", 
        "UNIUSDT", "NEARUSDT", "APTUSDT", "FILUSDT", "ICPUSDT",
        "PEPEUSDT", "WIFUSDT", "SUIUSDT", "FETUSDT"
    ]
    crypto_data = []
    try:
        url = "https://api.binance.com/api/v3/ticker/24hr"
        response = requests.get(url, timeout=5)
        if response.status_code == 200:
            all_tickers = {t['symbol']: t for t in response.json()}
            for sym in symbols:
                if sym in all_tickers:
                    ticker = all_tickers[sym]
                    symbol_clean = sym.replace('USDT', '')
                    price = float(ticker['lastPrice'])
                    change_24h = float(ticker['priceChangePercent'])
                    volume = float(ticker['volume'])
                    
                    if price >= 1000: price_str = f"${price:,.0f}"
                    elif price >= 1: price_str = f"${price:,.2f}"
                    else: price_str = f"${price:.4f}"
                    
                    if volume >= 1000000: vol_str = f"{volume/1000000:.1f}M"
                    elif volume >= 1000: vol_str = f"{volume/1000:.1f}K"
                    else: vol_str = f"{volume:.0f}"
                    
                    crypto_data.append({
                        "symbol": symbol_clean,
                        "price": price_str,
                        "change": change_24h,
                        "volume": vol_str,
                        "trend": "up" if change_24h > 0 else "down"
                    })
    except: pass 
    if not crypto_data:
        crypto_data = [{"symbol": "BTC", "price": "$94,250", "change": 2.3, "volume": "25.5B", "trend": "up"}]
    return crypto_data

# --- ğŸ”¥ B. Categorized News Fetcher ---
@st.cache_data(ttl=300)
def fetch_categorized_news_v2():
    def fetch_rss(url, limit=20):
        items = []
        try:
            feed = feedparser.parse(url)
            for entry in feed.entries[:limit]:
                time_display = "Recent"
                if hasattr(entry, 'published_parsed'):
                    try:
                        dt = datetime.datetime.fromtimestamp(time.mktime(entry.published_parsed))
                        diff = datetime.datetime.now() - dt
                        if diff.total_seconds() < 3600: time_display = f"{int(diff.total_seconds()/60)}m ago"
                        else: time_display = f"{int(diff.total_seconds()/3600)}h ago"
                    except: pass
                items.append({
                    "title": entry.title,
                    "source": entry.get("source", {}).get("title", "News"),
                    "link": entry.link,
                    "time": time_display
                })
        except: pass
        return items

    feeds = {
        "all": "https://news.google.com/rss?hl=en-US&gl=US&ceid=US:en",
        "politics": "https://rss.nytimes.com/services/xml/rss/nyt/Politics.xml",
        "tech": "https://techcrunch.com/feed/",
        "web3": "https://www.coindesk.com/arc/outboundfeeds/rss/"
    }
    return {k: fetch_rss(v, 30) for k, v in feeds.items()}

# --- ğŸ”¥ C. Polymarket Fetcher (ENHANCED - supports Sub-markets & Liquidity) ---
def process_polymarket_event(event):
    """
    Core function to process ANY Polymarket event.
    Returns standardized data structure tailored for generate_market_context.
    """
    try:
        title = event.get('title', 'Untitled').strip()
        if not title: return None
        
        # 1. Sensitive Keyword Filter
        SENSITIVE_KEYWORDS = ["china", "chinese", "xi jinping", "taiwan", "ccp", "beijing", "hong kong", "communist"]
        if any(kw in title.lower() for kw in SENSITIVE_KEYWORDS): return None

        # 2. Status Filter
        if event.get('closed') is True: return None
        if not event.get('markets'): return None
        
        # 3. Find Main Market (Highest Volume)
        markets_list = event.get('markets', [])
        markets_list.sort(key=lambda x: float(x.get('volume', 0) or 0), reverse=True)
        m = markets_list[0]
        
        vol = float(m.get('volume', 0) or 0)
        if vol < 1000: return None # Filter Dead Markets
        
        # --- NEW: Extract Data for Context Generator ---
        # Liquidity
        liquidity = float(m.get('liquidity', 0) or 0)
        
        # 24h Price Change
        change_24h = float(m.get('oneDayPriceChange', 0) or m.get('priceChange24h', 0) or 0)

        # Volume String Formatting
        if vol >= 1000000: vol_str = f"${vol/1000000:.1f}M"
        elif vol >= 1000: vol_str = f"${vol/1000:.0f}K"
        else: vol_str = f"${vol:.0f}"

        # 4. Parse Odds (Robust)
        outcomes = json.loads(m.get('outcomes')) if isinstance(m.get('outcomes'), str) else m.get('outcomes')
        prices = json.loads(m.get('outcomePrices')) if isinstance(m.get('outcomePrices'), str) else m.get('outcomePrices')
        
        outcome_data = []
        if outcomes and prices:
            for i, out in enumerate(outcomes):
                if i < len(prices):
                    try:
                        # Price is usually 0.72 in API, convert to percentage for list, keep decimal for context
                        raw_price = float(prices[i]) 
                        prob_percent = raw_price * 100
                        outcome_data.append((str(out), prob_percent, raw_price))
                    except: continue
        
        if not outcome_data: return None

        # Sort by Probability (High to Low)
        outcome_data.sort(key=lambda x: x[1], reverse=True)
        
        # Get Top Probability (0.0 - 1.0 format) for the Generator
        top_prob_decimal = outcome_data[0][2] 
        
        # Format Top 3 Odds for Display
        top_odds = [f"{o}: {p:.1f}%" for o, p, r in outcome_data[:3]]
        odds_str = " | ".join(top_odds)

        # 5. Extract Details for All Sub-Markets (V1.3 UPGRADE)
        all_sub_markets = []
        # We process the top 6 sub-markets to provide rich context
        for sub_m in markets_list[:6]:
            try:
                # Basic sub-market data
                q_text = sub_m.get('question', title)
                sub_out = json.loads(sub_m.get('outcomes')) if isinstance(sub_m.get('outcomes'), str) else sub_m.get('outcomes')
                sub_pri = json.loads(sub_m.get('outcomePrices')) if isinstance(sub_m.get('outcomePrices'), str) else sub_m.get('outcomePrices')
                sub_vol = float(sub_m.get('volume', 0) or 0)
                
                # Determine top outcome for this sub-market
                best_opt = ""
                best_price = 0.0
                if sub_out and sub_pri:
                    temp_ops = []
                    for i, o in enumerate(sub_out):
                        if i < len(sub_pri):
                            try:
                                p_val = float(sub_pri[i])
                                temp_ops.append((o, p_val))
                            except: continue
                    temp_ops.sort(key=lambda x: x[1], reverse=True)
                    if temp_ops:
                        best_opt = temp_ops[0][0]
                        best_price = temp_ops[0][1]

                # Structure for UI
                sub_data = {
                    "question": q_text,
                    "volume": sub_vol,
                    "type": "binary" if len(sub_out) == 2 else "multiple",
                    "options": [],
                    # Extra fields for Context Generator
                    "top_option": best_opt,
                    "top_price": best_price
                }
                
                # Fill options for UI
                if len(sub_out) == 2 and "Yes" in sub_out and "No" in sub_out:
                    y_idx = sub_out.index("Yes")
                    n_idx = sub_out.index("No")
                    sub_data['yes_price'] = float(sub_pri[y_idx]) * 100 if y_idx < len(sub_pri) else 0
                    sub_data['no_price'] = float(sub_pri[n_idx]) * 100 if n_idx < len(sub_pri) else 0
                else:
                    for i, o in enumerate(sub_out):
                        if i < len(sub_pri):
                            sub_data['options'].append({
                                "option": str(o), 
                                "price": float(sub_pri[i]) * 100
                            })
                all_sub_markets.append(sub_data)
            except: continue

        # Return standardized dict matching generate_market_context requirements
        return {
            "title": title,
            "slug": event.get('slug', ''),
            "volume": vol,
            "vol_str": vol_str, # This is the formatted string (e.g. $50M)
            "odds": odds_str,
            "url": f"https://polymarket.com/event/{event.get('slug', '')}",
            "markets": all_sub_markets,
            
            # Fields specifically for generate_market_context:
            "probability": top_prob_decimal, # 0.72
            "liquidity": liquidity,          # 150000.0
            "change_24h": change_24h         # 0.05
        }
    except: return None

@st.cache_data(ttl=60)
def fetch_polymarket_v5_simple(limit=60, sort_mode='volume'):
    """
    Fetch Top Markets for Homepage.
    Supports server-side sorting with robust fallback.
    """
    try:
        base_url = "https://gamma-api.polymarket.com/events?closed=false"
        
        # 1. Attempt API Sorting (Try sorting by volume or liquidity)
        if sort_mode == 'volume':
            # Try getting top liquidity/volume events (API dependent)
            # Increased limit to 500 to catch old whales if API sort fails
            api_url = f"{base_url}&limit=500" 
        else:
            # Active/Trending
            api_url = f"{base_url}&limit=50"

        resp = requests.get(api_url, timeout=12) 
        
        # Fallback if API fails
        if resp.status_code != 200:
            return []

        data = resp.json()
        markets = []
        
        if isinstance(data, list):
            for event in data:
                market_data = process_polymarket_event(event)
                if market_data:
                    markets.append(market_data)
        
        # 2. Strong Local Sort (Crucial for "Volume" view)
        if sort_mode == 'volume':
            markets.sort(key=lambda x: x['volume'], reverse=True)
        # 'active' usually implies the default API return order (Trending)
            
        return markets[:limit]
    except Exception as e:
        return []

# --- ğŸ”¥ ROBUST FACT CHECKER (Exa V2.1 Auto-Fallback) ---
def verify_news_with_exa(query):
    """
    Searches EXA for the news topic itself (not just markets) to verify authenticity.
    Uses 'auto' type which is the most robust.
    """
    if not EXA_AVAILABLE or not EXA_API_KEY: 
        return "âš ï¸ æ— æ³•è¿›è¡Œå…¨ç½‘äº‹å®æ ¸æŸ¥ (Exa API æœªé…ç½®)ã€‚"
    
    try:
        exa = Exa(EXA_API_KEY)
        
        # ğŸ”¥ Stability Update: Try Neural -> Fallback to Keyword
        try:
            search_resp = exa.search(
                f"{query}",
                num_results=3,
                type="neural"
            )
        except:
            # Fallback for stability
            search_resp = exa.search(
                f"{query}",
                num_results=3,
                type="keyword"
            )
        
        if not search_resp.results:
            return "âš ï¸ **äº‹å®æ ¸æŸ¥è­¦æŠ¥**ï¼šå…¨ç½‘æœªæœç´¢åˆ°ä¸æ­¤äº‹ä»¶ç›´æ¥ç›¸å…³çš„æƒå¨æ–°é—»æŠ¥é“ã€‚è¿™å¯èƒ½æ˜¯ä¸€åˆ™å‡æ–°é—»ï¼Œæˆ–è€…æ˜¯å°šæœªè¢«ä¸»æµåª’ä½“æŠ¥é“çš„ä¼ é—»ã€‚è¯·ä¿æŒé«˜åº¦æ€€ç–‘ã€‚"
            
        articles = []
        for r in search_resp.results:
            # Handle potential missing attributes gracefully
            date_str = getattr(r, 'published_date', 'Recent')
            title = getattr(r, 'title', 'News Article')
            url = getattr(r, 'url', '#')
            # Extract domain
            domain = urllib.parse.urlparse(url).netloc.replace('www.', '')
            articles.append(f"- [{title}]({url}) (Via {domain})")
            
        articles_text = "\n".join(articles)
        return f"âœ… **å…¨ç½‘äº‹å®æ ¸æŸ¥ (Web Fact Check)**:\n{articles_text}\n\n(AIå°†åŸºäºä¸Šè¿°æœç´¢ç»“æœéªŒè¯äº‹ä»¶çœŸå®æ€§)"
    except Exception as e:
        return f"âš ï¸ äº‹å®æ ¸æŸ¥æœåŠ¡æš‚æ—¶ä¸å¯ç”¨: {str(e)}"

def search_market_data_list(user_query):
    """
    Search Markets with Fallback Logic to handle missing keywords.
    """
    candidates = []
    seen_slugs = set()
    
    # 1. Generate English Keywords (Crucial for Chinese inputs)
    keywords = generate_keywords(user_query) 
    
    # Define search terms: [Generated Keywords, Raw Input]
    search_terms = []
    if keywords: search_terms.append(keywords)
    # If keywords look like a sentence, also try just the first few words as a broad search
    if keywords and len(keywords.split()) > 3:
         search_terms.append(" ".join(keywords.split()[:2])) 

    # --- Engine A: Direct Polymarket API Search ---
    # This is the fastest way if we have a good keyword
    for term in search_terms:
        if not term: continue
        try:
            encoded_kw = urllib.parse.quote(term)
            direct_url = f"https://gamma-api.polymarket.com/events?q={encoded_kw}&limit=10&closed=false"
            direct_resp = requests.get(direct_url, timeout=5)
            
            if direct_resp.status_code == 200:
                direct_data = direct_resp.json()
                if isinstance(direct_data, list):
                    for event in direct_data:
                        # ğŸ›¡ï¸ FILTER: Title must match keywords roughly
                        title = event.get('title', '').lower()
                        kw_lower = term.lower()
                        # Simple relevance check: at least one significant word must match
                        if any(w in title for w in kw_lower.split() if len(w)>3):
                            slug = event.get('slug')
                            if slug and slug not in seen_slugs:
                                market_data = process_polymarket_event(event)
                                if market_data:
                                    candidates.append(market_data)
                                    seen_slugs.add(slug)
        except: pass
    
    # --- Engine B: Exa Search (Secondary) ---
    # Only run if we have fewer than 5 results from direct API
    if EXA_AVAILABLE and EXA_API_KEY and len(candidates) < 5 and keywords:
        try:
            exa = Exa(EXA_API_KEY)
            
            # ğŸ”¥ Stability: Try Neural -> Fallback Keyword
            try:
                search_resp = exa.search(
                    f"site:polymarket.com {keywords}",
                    num_results=10, 
                    type="neural",
                    include_domains=["polymarket.com"]
                )
            except:
                search_resp = exa.search(
                    f"site:polymarket.com {keywords}",
                    num_results=10, 
                    type="keyword",
                    include_domains=["polymarket.com"]
                )
            
            for result in search_resp.results:
                match = re.search(r'polymarket\.com/event/([^/]+)', result.url)
                if match:
                    # Critical: Clean slug to avoid 404s
                    slug_raw = match.group(1)
                    slug = slug_raw.split('?')[0]
                    
                    if slug in seen_slugs: continue
                    seen_slugs.add(slug)
                    
                    api_url = f"https://gamma-api.polymarket.com/events?slug={slug}"
                    data = requests.get(api_url, timeout=5).json()
                    
                    if data and isinstance(data, list):
                        # ğŸ›¡ï¸ FILTER HERE TOO
                        title = data[0].get('title', '').lower()
                        if any(w in title for w in keywords.lower().split() if len(w)>3):
                            market_data = process_polymarket_event(data[0])
                            if market_data:
                                candidates.append(market_data)
        except: pass
    
    return candidates

# --- ğŸ”¥ D. AGENT LOGIC (GEMINI) ---
def generate_keywords(user_text):
    try:
        model = genai.GenerativeModel('gemini-2.5-flash')
        # Explicit instruction to translate and simplify
        prompt = f"Translate this news topic into 2-3 simple English keywords for searching on Polymarket. Example: 'SpaceXä¸Šå¸‚' -> 'SpaceX IPO'. Input: {user_text}"
        resp = model.generate_content(prompt)
        return resp.text.strip()
    except: return user_text

def is_chinese_input(text):
    return bool(re.search(r'[\u4e00-\u9fff]', text))

def generate_market_context(market_data, is_cn=True):
    if not market_data:
        if is_cn: return "âŒ **æ— ç›´æ¥é¢„æµ‹å¸‚åœºæ•°æ®** (No direct prediction market found)."
        else: return "âŒ **NO DIRECT MARKET DATA**."

    title = market_data.get('title', 'N/A')
    prob = market_data.get('probability', 0)
    volume = market_data.get('vol_str', 'N/A') 
    liquidity = market_data.get('liquidity', 0)
    change_24h = market_data.get('change_24h', 0)
    url = market_data.get('url', '#')
    
    trend_text = "ä¸Šæ¶¨" if change_24h > 0 else "ä¸‹è·Œ" if change_24h < 0 else "æŒå¹³"
    confidence_text = "é«˜" if liquidity > 100000 else "ä¸­ç­‰" if liquidity > 10000 else "è¾ƒä½"
    
    trend_text_en = "up" if change_24h > 0 else "down" if change_24h < 0 else "flat"
    confidence_text_en = "High" if liquidity > 100000 else "Medium" if liquidity > 10000 else "Low"

    sub_markets_str = ""
    if market_data.get('markets'):
        sub_items = []
        for sm in market_data['markets']:
            q = sm.get('question', 'Sub-market')
            top = sm.get('top_option', 'N/A')
            price = sm.get('top_price', 0) * 100
            item = f"- **{q}**: å€¾å‘äº **{top}** ({price:.1f}%)" if is_cn else f"- **{q}**: Leaning **{top}** ({price:.1f}%)"
            sub_items.append(item)
        sub_markets_str = "\n".join(sub_items)

    if is_cn:
        market_context = f"""
### âœ… å¸‚åœºçœŸå®èµ„é‡‘å…±è¯†ï¼ˆæ¥è‡ªPolymarketï¼‰

**ğŸ“Š æ ¸å¿ƒæŒ‡æ ‡é€Ÿè§ˆ**
* **é¢„æµ‹é—®é¢˜ï¼š** [{title}]({url})
* **å½“å‰éšå«æ¦‚ç‡ï¼š** **{prob:.0%}** ï¼ˆè¾ƒ24å°æ—¶å‰ **{trend_text} {abs(change_24h):.1%}**ï¼‰
* **å¸‚åœºæµåŠ¨æ€§ï¼š** ${liquidity:,.0f} ï¼ˆå…±è¯†ç½®ä¿¡åº¦ï¼š**{confidence_text}**ï¼‰
* **è¿‘æœŸäº¤æ˜“é‡ï¼š** {volume}

**ğŸ§© ç›¸å…³ç»†åˆ†å¸‚åœºå‚è€ƒ (Sub-Markets)**
{sub_markets_str}

**ğŸ’¡ ä½ çš„æ–°é—»å…±è¯†æ¢æµ‹å™¨è§£è¯»**
1. **å¸‚åœºå®šä»· vs. æ–°é—»æƒ…ç»ª**ï¼šå½“å‰å¸‚åœºè®¤ä¸ºæ­¤äº‹å‘ç”Ÿçš„å¯èƒ½æ€§ä¸º **{prob:.0%}**ã€‚å¦‚æœä½ çš„æ–°é—»æºæ˜¾å¾—æ›´ä¹è§‚æˆ–æ›´æ‚²è§‚ï¼Œå°±å­˜åœ¨å€¼å¾—æ¢ç©¶çš„â€œé¢„æœŸå·®â€ã€‚
2. **å…±è¯†å¼ºåº¦ä¸è¶‹åŠ¿**ï¼šå¸‚åœºä¿¡å¿ƒæ­£åœ¨ **{trend_text}**ï¼Œä¸”æµåŠ¨æ€§æ°´å¹³è¡¨æ˜è¯¥å…±è¯†çš„å¯é æ€§ **{confidence_text}**ã€‚
3. **ä½¿ç”¨å»ºè®®**ï¼šå¯å°†æ­¤ **{prob:.0%}** çš„æ¦‚ç‡ä½œä¸ºä½ åˆ¤æ–­è¯¥æ–°é—»å¯ä¿¡åº¦çš„**ä¸­æ€§åŸºå‡†**ã€‚è‹¥æ–°é—»è§‚ç‚¹ä¸æ­¤æ¦‚ç‡åç¦»æå¤§ï¼Œè¯·åŠ¡å¿…è­¦æƒ•å¹¶å¯»æ‰¾æ›´å¤šä½è¯ã€‚
"""
    else:
        market_context = f"""
### âœ… Real-Money Market Consensus (via Polymarket)

**ğŸ“Š Key Metrics**
* **Market:** [{title}]({url})
* **Implied Probability:** **{prob:.0%}** ({trend_text_en} {abs(change_24h):.1%} in 24h)
* **Market Liquidity:** ${liquidity:,.0f} (Confidence: **{confidence_text_en}**)
* **Recent Volume:** {volume}

**ğŸ§© Sub-Market Context**
{sub_markets_str}

**ğŸ’¡ Your Consensus Detector's Take**
1. **Market vs. News Hype:** The market prices a **{prob:.0%}** chance. Any significant deviation in your news source suggests a **mispricing** to investigate.
2. **Strength & Trend:** Consensus is **{trend_text_en}**, with **{confidence_text_en}** reliability due to liquidity.
3. **How to Use This:** Treat **{prob:.0%}** as your **neutral baseline** for credibility. Be skeptical if news narratives deviate wildly from this anchor.
"""
    return market_context

def get_agent_response(history, market_data):
    model = genai.GenerativeModel('gemini-2.5-flash')
    current_date = datetime.datetime.now().strftime("%Y-%m-%d")
    first_query = history[0]['content'] if history else ""
    is_cn = is_chinese_input(first_query)
    
    # 1. Market Context
    market_context = generate_market_context(market_data, is_cn)
    
    # 2. ğŸ”¥ Fact Check via Exa (Simplified call)
    fact_check_info = verify_news_with_exa(first_query)
    
    combined_context = f"{fact_check_info}\n\n{market_context}"

    # 3. System Prompt (Integrated Polymarket Trading Strategy)
    if is_cn:
        system_prompt = f"""
        ä½ æ˜¯ä¸€ä½ç®¡ç†äº¿çº§ç¾å…ƒèµ„é‡‘çš„ **å…¨çƒå®è§‚å¯¹å†²åŸºé‡‘ç»ç† (Global Macro PM)**ã€‚
        å½“å‰æ—¥æœŸ: {current_date}
        
        **æ ¸å¿ƒæŒ‡ä»¤:**
        1. **ç›´æ¥è¾“å‡º:** ä¸è¦è‡ªæˆ‘ä»‹ç»ï¼Œç›´æ¥å¼€å§‹åˆ†æã€‚
        2. **é€»è¾‘è‡ªæ´½:** ä¸¥ç¦é€»è¾‘æ–­å±‚ã€‚
        3. **å¼ºåˆ¶é“¾æ¥:** æåˆ°æ ‡çš„æ—¶å¿…é¡»åŠ é“¾æ¥ (å¦‚ [NVDA](https://finance.yahoo.com/quote/NVDA))ã€‚
        4. **è¯­è¨€å¼ºåˆ¶:** **å¿…é¡»å…¨ç¨‹ä½¿ç”¨ä¸­æ–‡å›ç­”**ã€‚
        5. **äº‹å®æ ¸æŸ¥:** åŸºäºä¸Šæ–¹æä¾›çš„å…¨ç½‘äº‹å®æ ¸æŸ¥ç»“æœè¿›è¡Œåˆ†æã€‚å¦‚æœæ ¸æŸ¥ç»“æœæ˜¾ç¤ºæ–°é—»å¯ç–‘æˆ–æ— æ³•éªŒè¯ï¼Œå¿…é¡»åœ¨åˆ†æä¸­æ˜ç¡®æŒ‡å‡ºé£é™©ã€‚

        {combined_context}
        
        --- åŸºé‡‘ç»ç†å†³ç­–å¤‡å¿˜å½• ---
        
        ### 0. æ–°é—»èƒŒæ™¯é€Ÿè§ˆ (Context)
        * **äº‹ä»¶è¿˜åŸ**: ç”¨é€šä¿—è¯­è¨€æ¦‚æ‹¬å‘ç”Ÿäº†ä»€ä¹ˆã€‚
        * **èƒŒæ™¯çŸ¥è¯†**: ä¸ºä»€ä¹ˆè¿™ä»¶äº‹å€¼å¾—å…³æ³¨ï¼Ÿ
        
        ### 1. å¸‚åœºæƒ…ç»ªä¸å…±è¯† (Market Sentiment & Consensus)
        * **å½“å‰å…±è¯†**: å¸‚åœºç›®å‰Price-inäº†ä»€ä¹ˆï¼ŸåŸºäºé¢„æµ‹å¸‚åœºæ•°æ®ï¼Œå¸‚åœºç›®å‰å¦‚ä½•çœ‹å¾…è¿™ä»¶äº‹ï¼Ÿå¸‚åœºæƒ…ç»ªæ˜¯ä¹è§‚è¿˜æ˜¯æ‚²è§‚ï¼Ÿ
        * **é¢„æœŸå·®**: ä½ çš„å·®å¼‚åŒ–è§‚ç‚¹æ˜¯ä»€ä¹ˆï¼Ÿ(ä¾‹å¦‚ï¼šå¸‚åœºååº”è¿‡åº¦/ååº”è¿Ÿé’)
        
        ### 2. å¤šè§’åº¦åˆ†æ (Multi-perspective Analysis)
        * **æ”¯æŒæ–¹è§‚ç‚¹**: å…³é”®ç†ç”±ä¸æ”¯æŒè€…ã€‚
        * **åå¯¹æ–¹è§‚ç‚¹**: å…³é”®ç†ç”±ä¸åå¯¹è€…ã€‚
        * **ç¬¬ä¸‰æ–¹/ä¸­ç«‹è§‚ç‚¹**: è¡¥å……è§†è§’ã€‚

        ### 3. äº‹å®æ ¸æŸ¥ä¸éªŒè¯ (Fact Check & Verification)
        * **ä¿¡æ¯æ¥æºå¯é æ€§**: è¯„ä¼°æ–°é—»æ¥æºçš„å¯ä¿¡åº¦ã€‚
        * **å…³é”®è¯æ®**: åˆ—å‡ºæ”¯æŒæˆ–åé©³è¯¥æ–°é—»çš„æ ¸å¿ƒäº‹å®ã€‚
        
        ### 4. å½±å“åˆ†æ (Impact Analysis)
        * **å¦‚æœå‘ç”Ÿ**: å¯¹è¡Œä¸šã€å¸‚åœºèµ„äº§çš„å…·ä½“å½±å“ã€‚
        * **å¦‚æœä¸å‘ç”Ÿ**: è‹¥æ ¸å¿ƒå‡è®¾å¤±æ•ˆï¼Œæœ€å¤§å›æ’¤é£é™©åœ¨å“ªé‡Œï¼Ÿ
        * **æ—¶é—´çº¿**: å…³é”®çš„æ—¶é—´èŠ‚ç‚¹ã€‚
        
        ### 5. äº¤æ˜“æ‰§è¡Œ (The Trade Book)
        
        #### A. ğŸ”® é¢„æµ‹å¸‚åœºç­–ç•¥ (Prediction Market Alpha)
        * **Polymarket æ ‡çš„**: [å¼•ç”¨ä¸Šæ–¹æä¾›çš„å¸‚åœºåç§°ï¼Œå¦‚æœæ²¡æœ‰åˆ™æ³¨æ˜æ— ]
        * **æ“ä½œå»ºè®®**: **ä¹°å…¥ YES** / **ä¹°å…¥ NO** / **è§‚æœ›**
        * **ä»·æ ¼ç­–ç•¥**: 
            * å½“å‰ä»·æ ¼: [å¡«å…¥ä»·æ ¼]
            * ç›®æ ‡å…¥åœºä»·: [å»ºè®®ä»·æ ¼]
            * **èƒœç‡èµ”ç‡åˆ†æ (EV)**: (ä¾‹å¦‚ï¼š"å½“å‰ä»·æ ¼30Â¢æš—ç¤º30%æ¦‚ç‡ï¼Œä½†æˆ‘åŸºäºæ–°é—»åˆ¤æ–­å®é™…æ¦‚ç‡ä¸º60%ï¼Œå­˜åœ¨å·¨å¤§çš„æ­£æœŸæœ›å€¼ã€‚")
        
        #### B. ğŸ“ˆ ä¼ ç»Ÿé‡‘èå¸‚åœº (TradFi / Crypto)
        * **æ ¸å¿ƒå¤šå¤´ (Long)**:
            * **æ ‡çš„**: [ä»£ç +é“¾æ¥] (å¦‚ç›¸å…³è‚¡ç¥¨æˆ–Token)
            * **é€»è¾‘**: ä¸ºä»€ä¹ˆè¿™ä¸ªèµ„äº§ä¼šå› ä¸ºè¯¥æ–°é—»å—ç›Šï¼Ÿ
        * **æ ¸å¿ƒç©ºå¤´/å¯¹å†² (Short/Hedge)**:
            * **æ ‡çš„**: [ä»£ç +é“¾æ¥]
            * **é€»è¾‘**: å¯¹å†²ä»€ä¹ˆé£é™©ï¼Ÿ
        
        ### 6. æœ€ç»ˆæŒ‡ä»¤ (PM Conclusion)
        * ä¸€å¥è¯æ€»ç»“äº¤æ˜“æ–¹å‘ï¼ˆçŠ€åˆ©ã€æœæ–­ï¼‰ã€‚
        """
    else:
        system_prompt = f"""
        You are a **Global Macro Portfolio Manager (PM)**.
        Current Date: {current_date}
        
        **INSTRUCTIONS:**
        1. **DIRECT START:** Do NOT introduce yourself. Start immediately.
        2. **LOGIC:** Maintain strict logical consistency.
        3. **LINKS:** Link all tickers (e.g. [AAPL](https://finance.yahoo.com/quote/AAPL)).
        4. **LANGUAGE:** English Only.
        5. **FACT CHECK:** Base your analysis on the fact-checking results provided above. If results show the news is suspicious or unverifiable, clearly highlight the risks in your analysis.

        {combined_context}
        
        --- INVESTMENT MEMORANDUM ---
        
        ### 0. News Context Snapshot (Context)
        * **Event Recap**: Summarize what happened in plain language.
        * **Background Knowledge**: Why does this matter?
        
        ### 1. Market Sentiment & Consensus (Market Sentiment & Consensus)
        * **Current Consensus**: What is currently Price-in by the market? Based on prediction market data, how does the market currently view this event? Is the market sentiment optimistic or pessimistic?
        * **The Gap**: What is your differentiated view? (e.g., Market overreaction/underreaction)
        
        ### 2. Multi-perspective Analysis (Multi-perspective Analysis)
        * **Proponent View**: Key reasons and supporters.
        * **Opponent View**: Key reasons and opponents.
        * **Neutral/Third-party View**: Additional perspectives.

        ### 3. Fact Check & Verification (Fact Check & Verification)
        * **Source Reliability**: Evaluate the credibility of the news source.
        * **Relevant Evidence**: List known facts supporting or refuting the news.
        
        ### 4. Impact Analysis (Impact Analysis)
        * **If It Happens**: Specific impacts on industries and assets.
        * **If It Doesn't Happen**: What is the downside risk if the core assumption fails?
        * **Timeline**: Key chronological milestones.
        
        ### 5. Trade Execution (The Trade Book)
        
        #### A. ğŸ”® Prediction Market Alpha
        * **Polymarket Target**: [Reference the market name above]
        * **Action**: **Buy YES** / **Buy NO** / **Wait**
        * **Pricing Strategy**: 
            * Current Price: [Insert Price]
            * Target Entry: [Suggested Price]
            * **EV Analysis**: (e.g., "Current price 30Â¢ implies 30% odds, but based on news I estimate 60% probability. Positive Expected Value.")
        
        #### B. ğŸ“ˆ Traditional Markets (TradFi / Crypto)
        * **Core Long (Long)**:
            * **Ticker**: [Code+Link]
            * **Logic**: Why will this asset benefit?
        * **Core Short/Hedge (Short/Hedge)**:
            * **Ticker**: [Code+Link]
            * **Logic**: What risk are we hedging?
            
        ### 6. Final Verdict (PM Conclusion)
        * One-sentence summary of trading direction.
        """
    
    api_messages = [{"role": "user", "parts": [system_prompt]}]
    for msg in history:
        role = "user" if msg['role'] == "user" else "model"
        api_messages.append({"role": role, "parts": [msg['content']]})
        
    try:
        # ğŸ”¥ CRITICAL FIX: Disable Safety Filters for Financial/Political Analysis
        safety_settings = {
            HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
            HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
            HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
            HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,
        }
        
        response = model.generate_content(api_messages, safety_settings=safety_settings)
        return response.text
    except Exception as e:
        return f"Agent Analysis Failed: {str(e)}"

# ================= ğŸ–¥ï¸ 6. MAIN LAYOUT =================

# --- Header ---
st.markdown('<div class="hero-title">BeHolmes News Analysis</div>', unsafe_allow_html=True)
st.markdown('<div class="hero-subtitle">Narrative vs. Reality Engine</div>', unsafe_allow_html=True)

# --- Search Bar & Workflow ---
_, s_mid, _ = st.columns([1, 6, 1])
with s_mid:
    def on_input_change():
        st.session_state.search_stage = "input"
        st.session_state.search_candidates = []
        
    input_val = st.session_state.get("user_news_text", "")
    # Use a unique key for the text area to allow programmatic clearing if needed, though we sync state
    user_query = st.text_area("Analyze News", value=input_val, height=70, 
                              placeholder="Paste a headline (e.g., 'Unitree robot on Spring Festival Gala')...", 
                              label_visibility="collapsed",
                              on_change=on_input_change, key="news_input_box")
    
    # === Step 1: SEARCH Button ===
    if st.session_state.search_stage == "input":
        if st.button("Begin Analysis", use_container_width=True):
            if st.session_state.news_input_box:
                st.session_state.user_news_text = st.session_state.news_input_box
                with st.spinner("ğŸ•µï¸â€â™‚ï¸ Hunting for prediction markets..."):
                    candidates = search_market_data_list(st.session_state.user_news_text)
                    st.session_state.search_candidates = candidates
                    st.session_state.search_stage = "selection"
                    st.rerun()

    # === Step 2: SELECTION List ===
    elif st.session_state.search_stage == "selection":
        st.markdown("##### ğŸ§ Select a Market to Reality Check:")
        
        # ğŸ”¥ UI FIX: Clearly show when no markets are found and offer News Analysis
        if not st.session_state.search_candidates:
            st.warning("âš ï¸ No direct prediction markets found matching your specific query.")
            st.markdown("---")
            if st.button("ğŸ“ Analyze News Only (AI Fact Check + Analysis)", use_container_width=True, type="primary"):
                st.session_state.current_market = None
                st.session_state.search_stage = "analysis"
                st.session_state.messages = [{"role": "user", "content": f"Analyze this news: {st.session_state.user_news_text}"}]
                st.rerun()
            
            if st.button("â¬…ï¸ Start Over"):
                st.session_state.search_stage = "input"
                st.rerun()
        else:
            # Loop through candidates
            for idx, m in enumerate(st.session_state.search_candidates):
                with st.container():
                    st.markdown(f"""
                    <div style="padding:12px; background:rgba(255,255,255,0.03); border-radius:8px; border:1px solid rgba(255,255,255,0.1); margin-bottom:10px;">
                        <div style="display:flex; justify-content:space-between; align-items:flex-start;">
                            <div style="flex:1;">
                                <div style="font-weight:700; font-size:1rem; color:#e5e7eb;">{m['title']}</div>
                                <div style="font-size:0.8rem; color:#9ca3af; margin-top:4px;">{m['odds']}</div>
                                <div style="font-size:0.75rem; color:#6b7280; font-family:'JetBrains Mono'; margin-top:4px;">Vol: {m['vol_str']}</div>
                            </div>
                        </div>
                    </div>
                    """, unsafe_allow_html=True)
                    if st.button("Analyze This", key=f"btn_{idx}", use_container_width=True):
                        st.session_state.current_market = m
                        st.session_state.search_stage = "analysis"
                        st.session_state.messages = [{"role": "user", "content": f"Analyze this news: {st.session_state.user_news_text}"}]
                        st.rerun()

            st.markdown("---")
            if st.button("ğŸ“ Analyze News Only (No Market)", use_container_width=True):
                st.session_state.current_market = None
                st.session_state.search_stage = "analysis"
                st.session_state.messages = [{"role": "user", "content": f"Analyze this news: {st.session_state.user_news_text}"}]
                st.rerun()
                
            if st.button("â¬…ï¸ Start Over"):
                st.session_state.search_stage = "input"
                st.rerun()

    # === Step 3: ANALYSIS Execution (Initial Run) ===
    elif st.session_state.search_stage == "analysis":
        if st.session_state.messages and st.session_state.messages[-1]['role'] == 'user':
            with st.spinner("ğŸ§  Generating Alpha Signals..."):
                response_text = get_agent_response(st.session_state.messages, st.session_state.current_market)
                st.session_state.messages.append({"role": "assistant", "content": response_text})
                st.rerun()

st.markdown("<br>", unsafe_allow_html=True)

# === DISPLAY ANALYSIS & CHAT (Interactive Mode) ===
if st.session_state.messages and st.session_state.search_stage == "analysis":
    
    if st.session_state.current_market:
        m = st.session_state.current_market
        # 1. Market Header (Native Metric Lookalike)
        with st.container():
            st.markdown(f"""
            <div style="background:rgba(20,0,0,0.8); border-left:4px solid #ef4444; padding:15px; border-radius:8px; margin-bottom:15px;">
                <div style="font-size:0.8rem; color:#9ca3af; text-transform:uppercase; letter-spacing:1px;">ğŸ¯ Selected Market</div>
                <div style="font-size:1.4rem; color:#ffffff; font-weight:800; margin:5px 0;">{m['title']}</div>
                <div style="font-family:'JetBrains Mono'; color:#ef4444; font-size:1rem;">{m['vol_str']} Volume</div>
                <a href="{m['url']}" target="_blank" style="display:inline-block; margin-top:10px; color:#fca5a5; font-size:0.8rem; text-decoration:none;">ğŸ”— Open on Polymarket</a>
            </div>
            """, unsafe_allow_html=True)

        # 2. Sub-Markets Loop (Native Streamlit)
        st.markdown("##### ğŸ“Š Sub-Market Details")
        for idx, market in enumerate(m.get('markets', []), 1):
            with st.container():
                st.markdown(f"**{idx}. {market['question']}**")
                
                if market['type'] == 'binary':
                    c1, c2 = st.columns(2)
                    with c1:
                        st.progress(market['yes_price'] / 100)
                        st.caption(f"Yes: {market['yes_price']:.1f}%")
                    with c2:
                        st.progress(market['no_price'] / 100)
                        st.caption(f"No: {market['no_price']:.1f}%")
                else:
                    try:
                        sorted_opts = sorted(market.get('options', []), key=lambda x: x.get('price', 0), reverse=True)[:3]
                    except: sorted_opts = []
                    
                    for opt in sorted_opts:
                        c1, c2 = st.columns([1, 4])
                        with c1:
                            st.write(f"{opt['price']:.1f}%")
                        with c2:
                            st.progress(min(opt['price'] / 100, 1.0))
                            st.caption(opt['option'])
                st.divider()

    else:
        st.info("ğŸ¤– Pure AI Analysis (No Market Data Selected)")

    # Chat History
    for msg in st.session_state.messages:
        if msg['role'] == 'user':
            with st.chat_message("user"):
                st.write(msg['content'].replace("Analyze this news: ", "News: "))
        else:
            with st.chat_message("assistant"):
                st.markdown(msg['content'])

    # Chat Input
    if prompt := st.chat_input("Ask a follow-up question..."):
        st.session_state.messages.append({"role": "user", "content": prompt})
        st.rerun()

    st.markdown("---")
    if st.button("â¬…ï¸ Start New Analysis"):
        st.session_state.messages = []
        st.session_state.search_stage = "input"
        st.rerun()

# ================= ğŸ–¥ï¸ DASHBOARD (Only if no analysis active) =================
if not st.session_state.messages and st.session_state.search_stage == "input":
    col_news, col_markets = st.columns([1, 1], gap="large")
    
    # === LEFT: News Feed ===
    with col_news:
        st.markdown("""
        <div style="display:flex; justify-content:space-between; align-items:center; margin-bottom:10px; border-bottom:1px solid rgba(220,38,38,0.3); padding-bottom:8px;">
            <div style="font-size:0.9rem; font-weight:700; color:#ef4444; letter-spacing:1px;">ğŸ“¡ LIVE NEWS STREAM</div>
            <div style="font-size:0.7rem; color:#ef4444;">â— LIVE</div>
        </div>
        """, unsafe_allow_html=True)

        trend_html = """
        <div class="trend-row">
            <a href="https://trends.google.com/trending?geo=US" target="_blank" class="trend-fixed-btn">ğŸ“ˆ Google Trends</a>
            <a href="https://twitter.com/explore/tabs/trending" target="_blank" class="trend-fixed-btn">ğŸ¦ Twitter Trends</a>
            <a href="https://www.jin10.com/" target="_blank" class="trend-fixed-btn">âš¡ Jin10 Data</a>
            <a href="https://www.bloomberg.com/" target="_blank" class="trend-fixed-btn">ğŸ“Š Bloomberg</a>
            <a href="https://www.reddit.com/r/all/" target="_blank" class="trend-fixed-btn">ğŸ¤– Reddit</a>
        </div>
        """
        st.markdown(trend_html, unsafe_allow_html=True)

        cat_cols = st.columns(4)
        cats = ["all", "politics", "web3", "tech"]
        labels = {"all": "ğŸŒ All", "politics": "ğŸ›ï¸ Politics", "web3": "â‚¿ Web3", "tech": "ğŸ¤– Tech"}
        for i, c in enumerate(cats):
            if cat_cols[i].button(labels[c], key=c, use_container_width=True):
                st.session_state.news_category = c
                st.rerun()

        @st.fragment(run_every=1)
        def render_news_feed():
            now_utc = datetime.datetime.now(datetime.timezone.utc)
            t_nyc = (now_utc - datetime.timedelta(hours=5)).strftime("%H:%M")
            t_lon = now_utc.strftime("%H:%M")
            t_abd = (now_utc + datetime.timedelta(hours=4)).strftime("%H:%M")
            t_bjs = (now_utc + datetime.timedelta(hours=8)).strftime("%H:%M")
            
            st.markdown(f"""
<div class="world-clock-bar">
    <span class="clock-item"><b>NYC</b> <span class="clock-time">{t_nyc}</span></span>
    <span class="clock-item"><b>LON</b> <span class="clock-time">{t_lon}</span></span>
    <span class="clock-item"><b>ABD</b> <span class="clock-time">{t_abd}</span></span>
    <span class="clock-item"><b>BJS</b> <span class="clock-time" style="color:#ef4444">{t_bjs}</span></span>
</div>
""", unsafe_allow_html=True)

            if st.session_state.news_category == "web3":
                data = fetch_crypto_prices_v2()
                if data:
                    rows = [data[i:i+2] for i in range(0, len(data), 2)]
                    for row in rows:
                        cols = st.columns(2)
                        for i, coin in enumerate(row):
                            color = "#10b981" if coin['trend'] == "up" else "#ef4444"
                            cols[i].markdown(f"""
                            <div style="background:rgba(0,0,0,0.4); border:1px solid rgba(255,255,255,0.1); border-left:3px solid {color}; border-radius:8px; padding:12px; margin-bottom:8px;">
                                <div style="display:flex; justify-content:space-between; margin-bottom:4px;">
                                    <span style="color:#e5e7eb; font-weight:700; font-size:0.9rem;">{coin['symbol']}</span>
                                    <span style="color:{color}; font-size:0.85rem;">{coin['change']:.2f}%</span>
                                </div>
                                <div style="display:flex; justify-content:space-between; align-items:center;">
                                    <span style="color:#fbbf24; font-weight:700; font-family:'JetBrains Mono'; font-size:1rem;">{coin['price']}</span>
                                    <a href="https://www.binance.com/en/trade/{coin['symbol']}_USDT" target="_blank" style="color:#ef4444; font-size:0.7rem; text-decoration:none; border:1px solid rgba(220,38,38,0.3); padding:2px 6px; border-radius:4px;">Trade</a>
                                </div>
                            </div>
                            """, unsafe_allow_html=True)
                else:
                    st.info("Loading crypto data...")
            else:
                all_news = fetch_categorized_news_v2()
                news_list = all_news.get(st.session_state.news_category, all_news['all'])
                if news_list:
                    rows = [news_list[i:i+2] for i in range(0, min(len(news_list), 24), 2)]
                    for row in rows:
                        cols = st.columns(2)
                        for i, news in enumerate(row):
                            cols[i].markdown(f"""
                            <div class="news-grid-card">
                                <div>
                                    <div class="news-meta"><span>{news['source']}</span><span style="color:#ef4444">{news['time']}</span></div>
                                    <div class="news-body">{news['title']}</div>
                                </div>
                                <a href="{news['link']}" target="_blank" style="text-decoration:none; color:#ef4444; font-size:0.8rem; font-weight:600; text-align:right; display:block; margin-top:10px;">ğŸ”— Read Source</a>
                            </div>
                            """, unsafe_allow_html=True)
                else:
                    st.info("No news available.")
        render_news_feed()

    # === RIGHT: Polymarket (Top 60) ===
    with col_markets:
        st.markdown('<div style="display:flex; justify-content:space-between; align-items:center; margin-bottom:10px; border-bottom:1px solid rgba(220,38,38,0.3); padding-bottom:8px;"><span style="font-size:0.9rem; font-weight:700; color:#ef4444;">ğŸ’° PREDICTION MARKETS (TOP VOLUME)</span></div>', unsafe_allow_html=True)
        
        sc1, sc2 = st.columns(2)
        if sc1.button("ğŸ’µ Volume", use_container_width=True): 
            st.session_state.market_sort = "volume"
            st.rerun() # Force Rerun to refresh list
        if sc2.button("ğŸ”¥ Activity", use_container_width=True): 
            st.session_state.market_sort = "active"
            st.rerun() # Force Rerun to refresh list
        
        # Pass sort_mode to fetcher
        markets = fetch_polymarket_v5_simple(60, sort_mode=st.session_state.market_sort)
        
        if markets:
            rows = [markets[i:i+2] for i in range(0, len(markets), 2)]
            for row in rows:
                cols = st.columns(2)
                for i, m in enumerate(row):
                    cols[i].markdown(f"""
                    <a href="https://polymarket.com/event/{m['slug']}" target="_blank" style="text-decoration:none;">
                        <div class="market-card-modern">
                            <div class="market-head">
                                <div class="market-title-mod">{m['title']}</div>
                                <div class="market-vol">{m['vol_str']}</div>
                            </div>
                        </div>
                    </a>
                    """, unsafe_allow_html=True)
        else:
            st.info("Loading markets...")

# ================= ğŸŒ 7. FOOTER =================
if not st.session_state.messages and st.session_state.search_stage == "input":
    st.markdown("---")
    st.markdown('<div style="text-align:center; color:#9ca3af; margin:25px 0; font-size:0.8rem; font-weight:700;">ğŸŒ GLOBAL INTELLIGENCE HUB</div>', unsafe_allow_html=True)
    
    links = [
        {"n": "Jin10", "u": "https://www.jin10.com/", "i": "ğŸ‡¨ğŸ‡³"},
        {"n": "WallStCN", "u": "https://wallstreetcn.com/live/global", "i": "ğŸ‡¨ğŸ‡³"},
        {"n": "Zaobao", "u": "https://www.zaobao.com.sg/realtime/world", "i": "ğŸ‡¸ğŸ‡¬"},
        {"n": "SCMP", "u": "https://www.scmp.com/", "i": "ğŸ‡­ğŸ‡°"},
        {"n": "Nikkei", "u": "https://asia.nikkei.com/", "i": "ğŸ‡¯ğŸ‡µ"},
        {"n": "Bloomberg", "u": "https://www.bloomberg.com/", "i": "ğŸ‡ºğŸ‡¸"},
        {"n": "Reuters", "u": "https://www.reuters.com/", "i": "ğŸ‡¬ğŸ‡§"},
        {"n": "TechCrunch", "u": "https://techcrunch.com/", "i": "ğŸ‡ºğŸ‡¸"},
        {"n": "CoinDesk", "u": "https://www.coindesk.com/", "i": "ğŸª™"},
        {"n": "Al Jazeera", "u": "https://www.aljazeera.com/", "i": "ğŸ‡¶ğŸ‡¦"},
    ]
    
    rows = [links[i:i+5] for i in range(0, len(links), 5)]
    for row in rows:
        cols = st.columns(5)
        for i, l in enumerate(row):
            cols[i].markdown(f"""
            <a href="{l['u']}" target="_blank" class="hub-btn">
                <div class="hub-content"><span class="hub-emoji">{l['i']}</span><span class="hub-text">{l['n']}</span></div>
            </a>
            """, unsafe_allow_html=True)
    st.markdown("<br><br>", unsafe_allow_html=True)
